{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Nathan Dang\n",
    "\n",
    "Partner: Charlie Poff-Webster\n",
    "\n",
    "Date: 04/07/2020\n",
    "\n",
    "DSCI225 - Applied Machine Learning\n",
    "\n",
    "Instructor: Prof. Basye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 - All the Bells and Whistles\n",
    "\n",
    "Our task in this lab was to complete Exercise 10 in Chapter 10 of the Hands-on ML textbook, in which we built a DNN for MNIST (the digits, not fashion), doing a careful job of finding a good learning rate and adding some \"bells and whistles.\"\n",
    "\n",
    "<b>NOTE</b>: we came up with our own approach which is different from the one suggested in the exercise's prompt because we didn't want to just copy and paste code from the solution. We marked checkpoints throughout our process which can be seen by the label of a progress log (i.e. \"Progress Log 1,\" \"Progress Log 2,\" etc) followed by a summary of what was going on on each checkpoint. The full documentation of the log can be found at the end of the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Log 1\n",
    "\n",
    "Import the tensorflow and keras package. The working envinronment must have tensorflow installed beforehand to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# import keras\n",
    "from tensorflow import keras\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "We were asked to use the MNIST dataset from tensorflow for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Log 2\n",
    "\n",
    "Import the keras package from tensorflow and get the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the full training set into a validation set and a (smaller) training set. Instead of using 5000 images for the validation set and the rest for training set, we splitted using the ratio 7:3, i.e. the training set had 42000 images and the validation set had 18000 images. Also, the values of the images stayed the same instead of being scaled like in the chapter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, random_state=100, train_size=0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have some visualisation of some images inside the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(y_train[index], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our Model\n",
    "\n",
    "Up to this point, we finished preparing our data for training and testing. Our task was to build a neural network that can achieve ~98% accuracy and the following is our attempts on making this happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Log 3\n",
    "\n",
    "Now, let's build our neural network. Initially, we built a random model with 3 layers, picked the learning rate of 0.001, and trained with 30 epochs as in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the model\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x16f29c45dc8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x16f29c57648>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x16f2608ce08>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x16f29c57108>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/30\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 1.5487 - accuracy: 0.7689 - val_loss: 0.4672 - val_accuracy: 0.8688\n",
      "Epoch 2/30\n",
      "48000/48000 [==============================] - 3s 68us/sample - loss: 0.3715 - accuracy: 0.8940 - val_loss: 0.3559 - val_accuracy: 0.9011\n",
      "Epoch 3/30\n",
      "48000/48000 [==============================] - 3s 68us/sample - loss: 0.2670 - accuracy: 0.9224 - val_loss: 0.2961 - val_accuracy: 0.9192\n",
      "Epoch 4/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.2130 - accuracy: 0.9370 - val_loss: 0.2598 - val_accuracy: 0.9304\n",
      "Epoch 5/30\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.1786 - accuracy: 0.9468 - val_loss: 0.2561 - val_accuracy: 0.9331\n",
      "Epoch 6/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.1553 - accuracy: 0.9535 - val_loss: 0.2448 - val_accuracy: 0.9375\n",
      "Epoch 7/30\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.1364 - accuracy: 0.9588 - val_loss: 0.2364 - val_accuracy: 0.9383\n",
      "Epoch 8/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.1194 - accuracy: 0.9637 - val_loss: 0.2178 - val_accuracy: 0.9457\n",
      "Epoch 9/30\n",
      "48000/48000 [==============================] - 3s 73us/sample - loss: 0.1070 - accuracy: 0.9671 - val_loss: 0.2290 - val_accuracy: 0.9434\n",
      "Epoch 10/30\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.0963 - accuracy: 0.9701 - val_loss: 0.2145 - val_accuracy: 0.9493\n",
      "Epoch 11/30\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.0853 - accuracy: 0.9736 - val_loss: 0.2096 - val_accuracy: 0.9496\n",
      "Epoch 12/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0779 - accuracy: 0.9763 - val_loss: 0.2091 - val_accuracy: 0.9503\n",
      "Epoch 13/30\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.0697 - accuracy: 0.9789 - val_loss: 0.2292 - val_accuracy: 0.9459\n",
      "Epoch 14/30\n",
      "48000/48000 [==============================] - 3s 68us/sample - loss: 0.0629 - accuracy: 0.9810 - val_loss: 0.2158 - val_accuracy: 0.9503\n",
      "Epoch 15/30\n",
      "48000/48000 [==============================] - 3s 68us/sample - loss: 0.0567 - accuracy: 0.9828 - val_loss: 0.2175 - val_accuracy: 0.9522\n",
      "Epoch 16/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0520 - accuracy: 0.9848 - val_loss: 0.2203 - val_accuracy: 0.9511\n",
      "Epoch 17/30\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.0477 - accuracy: 0.9858 - val_loss: 0.2192 - val_accuracy: 0.9517\n",
      "Epoch 18/30\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.0433 - accuracy: 0.9882 - val_loss: 0.2188 - val_accuracy: 0.9522\n",
      "Epoch 19/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0396 - accuracy: 0.9885 - val_loss: 0.2292 - val_accuracy: 0.9517\n",
      "Epoch 20/30\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.0358 - accuracy: 0.9899 - val_loss: 0.2345 - val_accuracy: 0.9524\n",
      "Epoch 21/30\n",
      "48000/48000 [==============================] - 3s 72us/sample - loss: 0.0334 - accuracy: 0.9908 - val_loss: 0.2332 - val_accuracy: 0.9549\n",
      "Epoch 22/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0306 - accuracy: 0.9918 - val_loss: 0.2324 - val_accuracy: 0.9543\n",
      "Epoch 23/30\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.0280 - accuracy: 0.9924 - val_loss: 0.2334 - val_accuracy: 0.9528\n",
      "Epoch 24/30\n",
      "48000/48000 [==============================] - 3s 69us/sample - loss: 0.0261 - accuracy: 0.9930 - val_loss: 0.2369 - val_accuracy: 0.9537\n",
      "Epoch 25/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.2378 - val_accuracy: 0.9540\n",
      "Epoch 26/30\n",
      "48000/48000 [==============================] - 4s 73us/sample - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.2461 - val_accuracy: 0.9538\n",
      "Epoch 27/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0205 - accuracy: 0.9944 - val_loss: 0.2429 - val_accuracy: 0.9542\n",
      "Epoch 28/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.2478 - val_accuracy: 0.9554\n",
      "Epoch 29/30\n",
      "48000/48000 [==============================] - 3s 70us/sample - loss: 0.0178 - accuracy: 0.9952 - val_loss: 0.2514 - val_accuracy: 0.9553\n",
      "Epoch 30/30\n",
      "48000/48000 [==============================] - 3s 71us/sample - loss: 0.0166 - accuracy: 0.9957 - val_loss: 0.2490 - val_accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/sample - loss: 0.2577 - accuracy: 0.9543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25766879551840555, 0.9543]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:</b> the model achieved the accuracy of 95.43% on the test set which was pretty good but still worse than the sample model given in the solution of exercise 10 in chapter 10 handson-ml notebook (~98%). Thus, we tried a few different methods to see if we can get a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Log 4\n",
    "\n",
    "First of all, we came up with a bunch of different different number of neurons per layer and different learning rate and chose the best combination for our model as shown in the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the model\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModels(testName, layer1, layer2, layer3, learningRate, epochNumber):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(layer1, activation=\"relu\"),\n",
    "        keras.layers.Dense(layer2, activation=\"relu\"),\n",
    "        keras.layers.Dense(layer3, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=learningRate),\n",
    "              metrics=[\"accuracy\"])\n",
    "    print(\"\\n\" + testName + \"\\nlayer1: \" + str(layer1) + \"\\nlayer2: \" + str(layer2), \"\\nlayer3: \" + str(layer3), \n",
    "         \"\\nlearningRate: \" + str(learningRate), \"\\nepochNumber: \" + str(epochNumber), \"\\n\")\n",
    "    history = model.fit(X_train, y_train, epochs=epochNumber,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test #1\n",
      "layer1: 300\n",
      "layer2: 300 \n",
      "layer3: 10 \n",
      "learningRate: 0.001 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 1.6408 - accuracy: 0.8744 - val_loss: 0.3949 - val_accuracy: 0.9197\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.2525 - accuracy: 0.9384 - val_loss: 0.3036 - val_accuracy: 0.9305\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 81us/sample - loss: 0.1451 - accuracy: 0.9601 - val_loss: 0.2622 - val_accuracy: 0.9425\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1013 - accuracy: 0.9707 - val_loss: 0.2491 - val_accuracy: 0.9455\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0714 - accuracy: 0.9788 - val_loss: 0.2433 - val_accuracy: 0.9469\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #2\n",
      "layer1: 300\n",
      "layer2: 500 \n",
      "layer3: 10 \n",
      "learningRate: 0.001 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 1.7179 - accuracy: 0.8796 - val_loss: 0.5487 - val_accuracy: 0.9175\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.2948 - accuracy: 0.9460 - val_loss: 0.4142 - val_accuracy: 0.9339\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 81us/sample - loss: 0.1519 - accuracy: 0.9654 - val_loss: 0.3669 - val_accuracy: 0.9399\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.0740 - accuracy: 0.9794 - val_loss: 0.3470 - val_accuracy: 0.9433\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.0409 - accuracy: 0.9877 - val_loss: 0.3359 - val_accuracy: 0.9478\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #3\n",
      "layer1: 500\n",
      "layer2: 300 \n",
      "layer3: 10 \n",
      "learningRate: 0.001 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 104us/sample - loss: 1.4700 - accuracy: 0.8746 - val_loss: 0.3538 - val_accuracy: 0.9112\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 98us/sample - loss: 0.2207 - accuracy: 0.9394 - val_loss: 0.2771 - val_accuracy: 0.9307\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.1392 - accuracy: 0.9581 - val_loss: 0.2537 - val_accuracy: 0.9425\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 96us/sample - loss: 0.0975 - accuracy: 0.9701 - val_loss: 0.2426 - val_accuracy: 0.9462\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.0724 - accuracy: 0.9781 - val_loss: 0.2389 - val_accuracy: 0.9459\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #4\n",
      "layer1: 500\n",
      "layer2: 500 \n",
      "layer3: 10 \n",
      "learningRate: 0.001 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 1.7482 - accuracy: 0.8986 - val_loss: 0.4885 - val_accuracy: 0.9348\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 0.2315 - accuracy: 0.9595 - val_loss: 0.4211 - val_accuracy: 0.9417\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 0.0879 - accuracy: 0.9789 - val_loss: 0.3452 - val_accuracy: 0.9513\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0366 - accuracy: 0.9892 - val_loss: 0.2988 - val_accuracy: 0.9548\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.3120 - val_accuracy: 0.9582\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #5\n",
      "layer1: 300\n",
      "layer2: 300 \n",
      "layer3: 20 \n",
      "learningRate: 0.001 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 92us/sample - loss: 1.6711 - accuracy: 0.8816 - val_loss: 0.4733 - val_accuracy: 0.9214\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.2708 - accuracy: 0.9441 - val_loss: 0.3635 - val_accuracy: 0.9360\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.1416 - accuracy: 0.9640 - val_loss: 0.3128 - val_accuracy: 0.9408\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.0841 - accuracy: 0.9760 - val_loss: 0.3033 - val_accuracy: 0.9457\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 91us/sample - loss: 0.0504 - accuracy: 0.9852 - val_loss: 0.2887 - val_accuracy: 0.9467\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #6\n",
      "layer1: 300\n",
      "layer2: 500 \n",
      "layer3: 20 \n",
      "learningRate: 0.001 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 1.7358 - accuracy: 0.8807 - val_loss: 0.5535 - val_accuracy: 0.9158\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.3070 - accuracy: 0.9439 - val_loss: 0.4314 - val_accuracy: 0.9317\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.1504 - accuracy: 0.9644 - val_loss: 0.3958 - val_accuracy: 0.9388\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 0.0834 - accuracy: 0.9782 - val_loss: 0.3640 - val_accuracy: 0.9428\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.0480 - accuracy: 0.9852 - val_loss: 0.3620 - val_accuracy: 0.9457\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #7\n",
      "layer1: 500\n",
      "layer2: 300 \n",
      "layer3: 20 \n",
      "learningRate: 0.001 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 1.5598 - accuracy: 0.8792 - val_loss: 0.3233 - val_accuracy: 0.9256\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 0.2147 - accuracy: 0.9408 - val_loss: 0.2654 - val_accuracy: 0.9351\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 103us/sample - loss: 0.1295 - accuracy: 0.9619 - val_loss: 0.2390 - val_accuracy: 0.9437\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.0902 - accuracy: 0.9722 - val_loss: 0.2216 - val_accuracy: 0.9477\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 106us/sample - loss: 0.0649 - accuracy: 0.9799 - val_loss: 0.2064 - val_accuracy: 0.9518\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #8\n",
      "layer1: 500\n",
      "layer2: 500 \n",
      "layer3: 20 \n",
      "learningRate: 0.001 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 1.7083 - accuracy: 0.8953 - val_loss: 0.4730 - val_accuracy: 0.9282\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.2209 - accuracy: 0.9561 - val_loss: 0.3218 - val_accuracy: 0.9477\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0919 - accuracy: 0.9766 - val_loss: 0.2960 - val_accuracy: 0.9519\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0384 - accuracy: 0.9887 - val_loss: 0.2847 - val_accuracy: 0.9538\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0175 - accuracy: 0.9951 - val_loss: 0.2673 - val_accuracy: 0.9575\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #9\n",
      "layer1: 300\n",
      "layer2: 300 \n",
      "layer3: 10 \n",
      "learningRate: 0.003 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 82us/sample - loss: 2.9379 - accuracy: 0.6648 - val_loss: 0.8277 - val_accuracy: 0.7850\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 73us/sample - loss: 0.6427 - accuracy: 0.8204 - val_loss: 0.5863 - val_accuracy: 0.8551\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 75us/sample - loss: 0.4037 - accuracy: 0.8974 - val_loss: 0.3709 - val_accuracy: 0.9091\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.3178 - accuracy: 0.9165 - val_loss: 0.3827 - val_accuracy: 0.9123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.2643 - accuracy: 0.9286 - val_loss: 0.3749 - val_accuracy: 0.9102\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #10\n",
      "layer1: 300\n",
      "layer2: 500 \n",
      "layer3: 10 \n",
      "learningRate: 0.003 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 94us/sample - loss: 2.7964 - accuracy: 0.5719 - val_loss: 0.8963 - val_accuracy: 0.8036\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 0.6729 - accuracy: 0.8550 - val_loss: 0.5680 - val_accuracy: 0.8851\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.4829 - accuracy: 0.8954 - val_loss: 0.5000 - val_accuracy: 0.8969\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 89us/sample - loss: 0.3857 - accuracy: 0.9135 - val_loss: 0.4242 - val_accuracy: 0.9092\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.3333 - accuracy: 0.9226 - val_loss: 0.4321 - val_accuracy: 0.9066\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #11\n",
      "layer1: 500\n",
      "layer2: 300 \n",
      "layer3: 10 \n",
      "learningRate: 0.003 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 5s 109us/sample - loss: 4.9723 - accuracy: 0.6683 - val_loss: 0.6678 - val_accuracy: 0.8576\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 108us/sample - loss: 0.5660 - accuracy: 0.8794 - val_loss: 0.5103 - val_accuracy: 0.8873\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 99us/sample - loss: 0.4327 - accuracy: 0.9054 - val_loss: 0.4226 - val_accuracy: 0.9112\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 97us/sample - loss: 0.3531 - accuracy: 0.9180 - val_loss: 0.3675 - val_accuracy: 0.9177\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 101us/sample - loss: 0.3006 - accuracy: 0.9286 - val_loss: 0.3672 - val_accuracy: 0.9151\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #12\n",
      "layer1: 500\n",
      "layer2: 500 \n",
      "layer3: 10 \n",
      "learningRate: 0.003 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 4.4316 - accuracy: 0.6269 - val_loss: 0.8250 - val_accuracy: 0.8219\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.6188 - accuracy: 0.8670 - val_loss: 0.6492 - val_accuracy: 0.8764\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.4676 - accuracy: 0.8980 - val_loss: 0.4606 - val_accuracy: 0.9079\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.3799 - accuracy: 0.9135 - val_loss: 0.4509 - val_accuracy: 0.9102\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.3230 - accuracy: 0.9228 - val_loss: 0.3849 - val_accuracy: 0.9169\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #13\n",
      "layer1: 300\n",
      "layer2: 300 \n",
      "layer3: 20 \n",
      "learningRate: 0.003 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 3.6889 - accuracy: 0.5502 - val_loss: 1.1260 - val_accuracy: 0.7406\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.9612 - accuracy: 0.7765 - val_loss: 1.0533 - val_accuracy: 0.7930\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 80us/sample - loss: 0.6418 - accuracy: 0.8512 - val_loss: 0.5768 - val_accuracy: 0.8727\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.4372 - accuracy: 0.9006 - val_loss: 0.4148 - val_accuracy: 0.9081\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 83us/sample - loss: 0.3505 - accuracy: 0.9165 - val_loss: 0.3774 - val_accuracy: 0.9087\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #14\n",
      "layer1: 300\n",
      "layer2: 500 \n",
      "layer3: 20 \n",
      "learningRate: 0.003 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 4s 93us/sample - loss: 5.4006 - accuracy: 0.3804 - val_loss: 1.7651 - val_accuracy: 0.4753\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 1.6158 - accuracy: 0.5053 - val_loss: 1.5163 - val_accuracy: 0.5038\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 4s 88us/sample - loss: 1.3437 - accuracy: 0.5710 - val_loss: 1.5809 - val_accuracy: 0.5090\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 4s 87us/sample - loss: 1.2567 - accuracy: 0.5830 - val_loss: 1.1068 - val_accuracy: 0.6217\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 4s 86us/sample - loss: 1.0634 - accuracy: 0.6329 - val_loss: 1.0820 - val_accuracy: 0.6578\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #15\n",
      "layer1: 500\n",
      "layer2: 300 \n",
      "layer3: 20 \n",
      "learningRate: 0.003 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 3.5939 - accuracy: 0.8595 - val_loss: 0.2676 - val_accuracy: 0.9247\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2129 - accuracy: 0.9356 - val_loss: 0.2336 - val_accuracy: 0.9310\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1593 - accuracy: 0.9520 - val_loss: 0.2076 - val_accuracy: 0.9429\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1288 - accuracy: 0.9601 - val_loss: 0.1990 - val_accuracy: 0.9474\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1084 - accuracy: 0.9659 - val_loss: 0.1746 - val_accuracy: 0.9532\n",
      "-------------------------------------------------------------\n",
      "\n",
      "Test #16\n",
      "layer1: 500\n",
      "layer2: 500 \n",
      "layer3: 20 \n",
      "learningRate: 0.003 \n",
      "epochNumber: 5 \n",
      "\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 3.2666 - accuracy: 0.8065 - val_loss: 0.5693 - val_accuracy: 0.8775\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 0.3971 - accuracy: 0.9110 - val_loss: 0.3910 - val_accuracy: 0.9123\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.2707 - accuracy: 0.9348 - val_loss: 0.3126 - val_accuracy: 0.9329\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.2059 - accuracy: 0.9477 - val_loss: 0.2928 - val_accuracy: 0.9361\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.1712 - accuracy: 0.9550 - val_loss: 0.2838 - val_accuracy: 0.9418\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "testLayer1 = [300, 300, 500, 500, 300, 300, 500, 500, 300, 300, 500, 500, 300, 300, 500, 500]\n",
    "testLayer2 = [300, 500, 300, 500, 300, 500, 300, 500, 300, 500, 300, 500, 300, 500, 300, 500]\n",
    "testLayer3 = [10, 10, 10, 10, 20, 20, 20, 20, 10, 10, 10, 10, 20, 20, 20, 20]\n",
    "testLearningRate = [1e-3, 1e-3, 1e-3, 1e-3, 1e-3, 1e-3, 1e-3, 1e-3, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003]\n",
    "testEpochNumber = 5\n",
    "\n",
    "for i in range(16):\n",
    "    testModels(\"Test #\" + str(i+1), testLayer1[i], testLayer2[i], testLayer3[i], testLearningRate[i], testEpochNumber)\n",
    "    print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:</b> from the result above, we chose the models from test 4 and 8 (as they had the best result) to fully train and this time we used the a different number of epochs (i.e. 50) to see if it yields a better result. Furthermore, starting from test #9, we can see that the loss went up with learning rate 0.003."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Log 5 & 6\n",
    "\n",
    "We defined a method that builds a neural network model with some given parameters and used this method to build separate models for the two test cases that we mentioned above (test 4 and 8) and evaluate both of them on the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden, n_neurons, n_softmax, learning_rate, input_shape=[28, 28]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons[layer], activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(n_softmax, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the model\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4\n",
    "n_hidden = 2\n",
    "neurons_per_layer = [500, 500]\n",
    "n_softmax = 10\n",
    "model4 = build_model(n_hidden, neurons_per_layer, n_softmax, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.7046 - accuracy: 0.8976 - val_loss: 0.4533 - val_accuracy: 0.9320\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 0.2079 - accuracy: 0.9581 - val_loss: 0.3251 - val_accuracy: 0.9460\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 7s 141us/sample - loss: 0.0873 - accuracy: 0.9770 - val_loss: 0.2939 - val_accuracy: 0.9531\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 0.0372 - accuracy: 0.9894 - val_loss: 0.3013 - val_accuracy: 0.9520\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.2795 - val_accuracy: 0.9553\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.2768 - val_accuracy: 0.9578\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.2783 - val_accuracy: 0.9581\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2773 - val_accuracy: 0.9595\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 9.9301e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9599\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 8.4148e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9600\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 7.3696e-04 - accuracy: 1.0000 - val_loss: 0.2799 - val_accuracy: 0.9603\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 6.6141e-04 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9605\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 6.0489e-04 - accuracy: 1.0000 - val_loss: 0.2809 - val_accuracy: 0.9613\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 5.5935e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9612\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 5.1692e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9613\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 4.8442e-04 - accuracy: 1.0000 - val_loss: 0.2822 - val_accuracy: 0.9613\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 4.5595e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9616\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 4.2969e-04 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9617\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 4.0714e-04 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9616\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 3.8796e-04 - accuracy: 1.0000 - val_loss: 0.2832 - val_accuracy: 0.9616\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 3.6901e-04 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9617\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 3.5344e-04 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9616\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 3.3869e-04 - accuracy: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9617\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 8s 158us/sample - loss: 3.2506e-04 - accuracy: 1.0000 - val_loss: 0.2840 - val_accuracy: 0.9617\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 3.1309e-04 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9620\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 3.0138e-04 - accuracy: 1.0000 - val_loss: 0.2844 - val_accuracy: 0.9620\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 2.9056e-04 - accuracy: 1.0000 - val_loss: 0.2847 - val_accuracy: 0.9621\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 2.8081e-04 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9621\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 2.7183e-04 - accuracy: 1.0000 - val_loss: 0.2851 - val_accuracy: 0.9621\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 6s 135us/sample - loss: 2.6333e-04 - accuracy: 1.0000 - val_loss: 0.2852 - val_accuracy: 0.9622\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 2.5545e-04 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 0.9622\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 2.4777e-04 - accuracy: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9624\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 2.4084e-04 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9624\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 2.3425e-04 - accuracy: 1.0000 - val_loss: 0.2860 - val_accuracy: 0.9623\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 2.2780e-04 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9622\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 2.2215e-04 - accuracy: 1.0000 - val_loss: 0.2863 - val_accuracy: 0.9622\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 2.1645e-04 - accuracy: 1.0000 - val_loss: 0.2866 - val_accuracy: 0.9623\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 2.1115e-04 - accuracy: 1.0000 - val_loss: 0.2867 - val_accuracy: 0.9624\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 2.0606e-04 - accuracy: 1.0000 - val_loss: 0.2868 - val_accuracy: 0.9624\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 2.0114e-04 - accuracy: 1.0000 - val_loss: 0.2870 - val_accuracy: 0.9625\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 1.9656e-04 - accuracy: 1.0000 - val_loss: 0.2872 - val_accuracy: 0.9624\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 6s 131us/sample - loss: 1.9229e-04 - accuracy: 1.0000 - val_loss: 0.2873 - val_accuracy: 0.9625\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.8805e-04 - accuracy: 1.0000 - val_loss: 0.2874 - val_accuracy: 0.9625\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.8392e-04 - accuracy: 1.0000 - val_loss: 0.2876 - val_accuracy: 0.9625\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 6s 133us/sample - loss: 1.8019e-04 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9625\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 1.7648e-04 - accuracy: 1.0000 - val_loss: 0.2877 - val_accuracy: 0.9627\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 1.7299e-04 - accuracy: 1.0000 - val_loss: 0.2879 - val_accuracy: 0.9626\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 7s 136us/sample - loss: 1.6967e-04 - accuracy: 1.0000 - val_loss: 0.2880 - val_accuracy: 0.9627\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 1.6640e-04 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9625\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 1.6314e-04 - accuracy: 1.0000 - val_loss: 0.2883 - val_accuracy: 0.9627\n"
     ]
    }
   ],
   "source": [
    "history = model4.fit(X_train, y_train, epochs=50,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 98us/sample - loss: 0.2775 - accuracy: 0.9603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27745574705852366, 0.9603]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the model\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 8\n",
    "n_hidden = 2\n",
    "neurons_per_layer = [500, 500]\n",
    "n_softmax = 20\n",
    "model8 = build_model(n_hidden, neurons_per_layer, n_softmax, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 1.7189 - accuracy: 0.8977 - val_loss: 0.4552 - val_accuracy: 0.9260\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 0.2147 - accuracy: 0.9562 - val_loss: 0.3307 - val_accuracy: 0.9430\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 0.0915 - accuracy: 0.9771 - val_loss: 0.2915 - val_accuracy: 0.9497\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 0.0436 - accuracy: 0.9871 - val_loss: 0.2773 - val_accuracy: 0.9521\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.2632 - val_accuracy: 0.9548\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 6s 130us/sample - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.2655 - val_accuracy: 0.9557\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 7s 137us/sample - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.2688 - val_accuracy: 0.9568\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.2695 - val_accuracy: 0.9572\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 6s 132us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2696 - val_accuracy: 0.9579\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9572\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9585\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 6s 134us/sample - loss: 8.9087e-04 - accuracy: 1.0000 - val_loss: 0.2741 - val_accuracy: 0.9584\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 8.0670e-04 - accuracy: 1.0000 - val_loss: 0.2744 - val_accuracy: 0.9582\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 7.3577e-04 - accuracy: 1.0000 - val_loss: 0.2747 - val_accuracy: 0.9585\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 6.7750e-04 - accuracy: 1.0000 - val_loss: 0.2757 - val_accuracy: 0.9582\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 6.3016e-04 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9588\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 5.8977e-04 - accuracy: 1.0000 - val_loss: 0.2761 - val_accuracy: 0.9582\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 5.5459e-04 - accuracy: 1.0000 - val_loss: 0.2766 - val_accuracy: 0.9584\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 6s 126us/sample - loss: 5.2446e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9587\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 4.9713e-04 - accuracy: 1.0000 - val_loss: 0.2771 - val_accuracy: 0.9588\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 4.7276e-04 - accuracy: 1.0000 - val_loss: 0.2775 - val_accuracy: 0.9588\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 4.5097e-04 - accuracy: 1.0000 - val_loss: 0.2776 - val_accuracy: 0.9589\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 4.3108e-04 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 0.9590\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 4.1313e-04 - accuracy: 1.0000 - val_loss: 0.2781 - val_accuracy: 0.9588\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 3.9696e-04 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9589\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 3.8191e-04 - accuracy: 1.0000 - val_loss: 0.2785 - val_accuracy: 0.9592\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 3.6770e-04 - accuracy: 1.0000 - val_loss: 0.2787 - val_accuracy: 0.9590\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 3.5461e-04 - accuracy: 1.0000 - val_loss: 0.2789 - val_accuracy: 0.9592\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 3.4212e-04 - accuracy: 1.0000 - val_loss: 0.2790 - val_accuracy: 0.9591\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 3.3129e-04 - accuracy: 1.0000 - val_loss: 0.2792 - val_accuracy: 0.9592\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 3.2085e-04 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9592\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 3.1093e-04 - accuracy: 1.0000 - val_loss: 0.2797 - val_accuracy: 0.9594\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 3.0211e-04 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9596\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 2.9314e-04 - accuracy: 1.0000 - val_loss: 0.2801 - val_accuracy: 0.9596\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 6s 125us/sample - loss: 2.8539e-04 - accuracy: 1.0000 - val_loss: 0.2802 - val_accuracy: 0.9597\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 2.7749e-04 - accuracy: 1.0000 - val_loss: 0.2803 - val_accuracy: 0.9597\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 2.7015e-04 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9599\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 2.6360e-04 - accuracy: 1.0000 - val_loss: 0.2807 - val_accuracy: 0.9598\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 2.5659e-04 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9597\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 2.5054e-04 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9600\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 2.4459e-04 - accuracy: 1.0000 - val_loss: 0.2812 - val_accuracy: 0.9600\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 2.3891e-04 - accuracy: 1.0000 - val_loss: 0.2811 - val_accuracy: 0.9599\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 2.3370e-04 - accuracy: 1.0000 - val_loss: 0.2813 - val_accuracy: 0.9602\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 2.2826e-04 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9601\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 6s 128us/sample - loss: 2.2345e-04 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9603\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 2.1849e-04 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9601\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 6s 124us/sample - loss: 2.1431e-04 - accuracy: 1.0000 - val_loss: 0.2820 - val_accuracy: 0.9602\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 6s 129us/sample - loss: 2.0993e-04 - accuracy: 1.0000 - val_loss: 0.2821 - val_accuracy: 0.9601\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 2.0564e-04 - accuracy: 1.0000 - val_loss: 0.2824 - val_accuracy: 0.9602\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 6s 127us/sample - loss: 2.0149e-04 - accuracy: 1.0000 - val_loss: 0.2825 - val_accuracy: 0.9603\n"
     ]
    }
   ],
   "source": [
    "history = model8.fit(X_train, y_train, epochs=50,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 88us/sample - loss: 0.2608 - accuracy: 0.9630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26083037926554237, 0.963]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model8.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:</b> the accuracy score did improve (~96%), but still not as good as our goal (i.e. 98%). But this result clarified that a more complex model in terms of number of neurons in each layer and more training epochs does help improve the performance. However, we had some doubts about how the higher number of epochs would improve the accuracy score, maybe it did, but definitely not significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Log 7\n",
    "\n",
    "At this point, we applied hyperparameters tuning (using Grid Search) to see if it helped improving the performance of the model. The idea was adapted from section \"Hyperparameters Tuning\" in the chapter 10 notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the model\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_keras(n_hidden=2, n_neurons=300, n_softmax=10, learning_rate=0.001, input_shape=[28, 28]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(n_softmax, activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 4s 85us/sample - loss: 1.6408 - accuracy: 0.8744 - val_loss: 0.3949 - val_accuracy: 0.9197\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.2525 - accuracy: 0.9384 - val_loss: 0.3036 - val_accuracy: 0.9305\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.1451 - accuracy: 0.9601 - val_loss: 0.2622 - val_accuracy: 0.9425\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.1013 - accuracy: 0.9707 - val_loss: 0.2491 - val_accuracy: 0.9455\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0714 - accuracy: 0.9788 - val_loss: 0.2433 - val_accuracy: 0.9469\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0522 - accuracy: 0.9844 - val_loss: 0.2392 - val_accuracy: 0.9485\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 4s 78us/sample - loss: 0.0406 - accuracy: 0.9879 - val_loss: 0.2504 - val_accuracy: 0.9482\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0319 - accuracy: 0.9908 - val_loss: 0.2379 - val_accuracy: 0.9508\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0247 - accuracy: 0.9940 - val_loss: 0.2344 - val_accuracy: 0.9518\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0199 - accuracy: 0.9951 - val_loss: 0.2337 - val_accuracy: 0.9528\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0154 - accuracy: 0.9969 - val_loss: 0.2378 - val_accuracy: 0.9536\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.2352 - val_accuracy: 0.9536\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.2417 - val_accuracy: 0.9539\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0085 - accuracy: 0.9988 - val_loss: 0.2428 - val_accuracy: 0.9533\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0072 - accuracy: 0.9991 - val_loss: 0.2418 - val_accuracy: 0.9545\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.2436 - val_accuracy: 0.9545\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 4s 79us/sample - loss: 0.0056 - accuracy: 0.9995 - val_loss: 0.2444 - val_accuracy: 0.9546\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.2458 - val_accuracy: 0.9544\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 4s 77us/sample - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.2504 - val_accuracy: 0.9548\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 4s 76us/sample - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.2489 - val_accuracy: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16f31669608>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/sample - loss: 0.2438 - accuracy: 0.9542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.24375572328867828"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.001509041041403342, n_hidden=2, n_neurons=271, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 3s 90us/sample - loss: 2.1547 - accuracy: 0.8406 - val_loss: 0.5680 - val_accuracy: 0.8852\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.3323 - accuracy: 0.9213 - val_loss: 0.4492 - val_accuracy: 0.9168\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.2067 - accuracy: 0.9455 - val_loss: 0.3894 - val_accuracy: 0.9251\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.1412 - accuracy: 0.9600 - val_loss: 0.3778 - val_accuracy: 0.9268\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0996 - accuracy: 0.9699 - val_loss: 0.3725 - val_accuracy: 0.9302\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0764 - accuracy: 0.9759 - val_loss: 0.3664 - val_accuracy: 0.9320\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0550 - accuracy: 0.9830 - val_loss: 0.3574 - val_accuracy: 0.9345\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0430 - accuracy: 0.9866 - val_loss: 0.3586 - val_accuracy: 0.9350\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0306 - accuracy: 0.9912 - val_loss: 0.3534 - val_accuracy: 0.9377\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.3531 - val_accuracy: 0.9413\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.3556 - val_accuracy: 0.9407\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0154 - accuracy: 0.9963 - val_loss: 0.3578 - val_accuracy: 0.9400\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.3611 - val_accuracy: 0.9424\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0104 - accuracy: 0.9975 - val_loss: 0.3602 - val_accuracy: 0.9426\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.3688 - val_accuracy: 0.9432\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.3664 - val_accuracy: 0.9433\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.3695 - val_accuracy: 0.9437\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.3716 - val_accuracy: 0.9440\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.3738 - val_accuracy: 0.9440\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.3745 - val_accuracy: 0.9450\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0052 - accuracy: 0.9991 - val_loss: 0.3785 - val_accuracy: 0.9447\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.3792 - val_accuracy: 0.9451\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.3819 - val_accuracy: 0.9458\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.3834 - val_accuracy: 0.9451\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.3840 - val_accuracy: 0.9455\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.3852 - val_accuracy: 0.9455\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.3869 - val_accuracy: 0.9450\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.3888 - val_accuracy: 0.9458\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.3897 - val_accuracy: 0.9465\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.3895 - val_accuracy: 0.9464\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.3934 - val_accuracy: 0.9457\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3930 - val_accuracy: 0.9456\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.3965 - val_accuracy: 0.9456\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.3948 - val_accuracy: 0.9466\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.3956 - val_accuracy: 0.9459\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.3960 - val_accuracy: 0.9457\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.3964 - val_accuracy: 0.9459\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0021 - accuracy: 0.9996 - val_loss: 0.3989 - val_accuracy: 0.9465\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.4002 - val_accuracy: 0.9465\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.4015 - val_accuracy: 0.9465\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.4020 - val_accuracy: 0.9459\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.4045 - val_accuracy: 0.9459\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.4040 - val_accuracy: 0.9466\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.4050 - val_accuracy: 0.9463\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.4048 - val_accuracy: 0.9467\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.4068 - val_accuracy: 0.9465\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.4079 - val_accuracy: 0.9466\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.4063 - val_accuracy: 0.9470\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.4079 - val_accuracy: 0.9468\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.4086 - val_accuracy: 0.9474\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.4090 - val_accuracy: 0.9469\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4103 - val_accuracy: 0.9467\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4114 - val_accuracy: 0.9470\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4124 - val_accuracy: 0.9468\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4131 - val_accuracy: 0.9471\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4139 - val_accuracy: 0.9472\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.4152 - val_accuracy: 0.9471\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4152 - val_accuracy: 0.9472\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4152 - val_accuracy: 0.9467\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.4157 - val_accuracy: 0.9471\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4180 - val_accuracy: 0.9467\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4176 - val_accuracy: 0.9467\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.4182 - val_accuracy: 0.9473\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.4207 - val_accuracy: 0.9461\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.4224 - val_accuracy: 0.9467\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.4199 - val_accuracy: 0.9473\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 9.9338e-04 - accuracy: 0.9998 - val_loss: 0.4202 - val_accuracy: 0.9470\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 9.6707e-04 - accuracy: 0.9998 - val_loss: 0.4216 - val_accuracy: 0.9471\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 9.4747e-04 - accuracy: 0.9998 - val_loss: 0.4221 - val_accuracy: 0.9471\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 9.2867e-04 - accuracy: 0.9998 - val_loss: 0.4240 - val_accuracy: 0.9463\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 9.1730e-04 - accuracy: 0.9998 - val_loss: 0.4229 - val_accuracy: 0.9475\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 9.0003e-04 - accuracy: 0.9998 - val_loss: 0.4234 - val_accuracy: 0.9467\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 8.9107e-04 - accuracy: 0.9998 - val_loss: 0.4244 - val_accuracy: 0.9473\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 8.8545e-04 - accuracy: 0.9998 - val_loss: 0.4248 - val_accuracy: 0.9469\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 8.5978e-04 - accuracy: 0.9998 - val_loss: 0.4257 - val_accuracy: 0.9473\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 8.3452e-04 - accuracy: 0.9998 - val_loss: 0.4258 - val_accuracy: 0.9474\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 8.1678e-04 - accuracy: 0.9998 - val_loss: 0.4259 - val_accuracy: 0.9472\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 8.1073e-04 - accuracy: 0.9998 - val_loss: 0.4268 - val_accuracy: 0.9469\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 8.1038e-04 - accuracy: 0.9998 - val_loss: 0.4273 - val_accuracy: 0.9475\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 7.9165e-04 - accuracy: 0.9998 - val_loss: 0.4271 - val_accuracy: 0.9472\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 7.6494e-04 - accuracy: 0.9998 - val_loss: 0.4279 - val_accuracy: 0.9478\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.4063 - accuracy: 0.9491\n",
      "[CV]  learning_rate=0.001509041041403342, n_hidden=2, n_neurons=271, n_softmax=10, total= 3.4min\n",
      "[CV] learning_rate=0.001509041041403342, n_hidden=2, n_neurons=271, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 3s 88us/sample - loss: 2.1442 - accuracy: 0.8522 - val_loss: 0.5633 - val_accuracy: 0.8948\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.2928 - accuracy: 0.9326 - val_loss: 0.3623 - val_accuracy: 0.9227\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.1566 - accuracy: 0.9572 - val_loss: 0.3324 - val_accuracy: 0.9367\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 81us/sample - loss: 0.0972 - accuracy: 0.9704 - val_loss: 0.3310 - val_accuracy: 0.9327\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0639 - accuracy: 0.9805 - val_loss: 0.3428 - val_accuracy: 0.9371\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.3265 - val_accuracy: 0.9400\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.3269 - val_accuracy: 0.9426\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0208 - accuracy: 0.9947 - val_loss: 0.3246 - val_accuracy: 0.9418\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0151 - accuracy: 0.9966 - val_loss: 0.3329 - val_accuracy: 0.9435\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.3276 - val_accuracy: 0.9452\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.3329 - val_accuracy: 0.9456\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.3410 - val_accuracy: 0.9444\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.3401 - val_accuracy: 0.9471\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.3404 - val_accuracy: 0.9464\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.3445 - val_accuracy: 0.9469\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.3450 - val_accuracy: 0.9463\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.3474 - val_accuracy: 0.9467\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9470\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.3499 - val_accuracy: 0.9472\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3529 - val_accuracy: 0.9474\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9471\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9475\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9475\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9473\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9484\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9480\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9479\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9484\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 81us/sample - loss: 9.6579e-04 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9484\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 9.2241e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9485\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.3191 - accuracy: 0.9522\n",
      "[CV]  learning_rate=0.001509041041403342, n_hidden=2, n_neurons=271, n_softmax=10, total= 1.3min\n",
      "[CV] learning_rate=0.001509041041403342, n_hidden=2, n_neurons=271, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 2.3384 - accuracy: 0.8502 - val_loss: 0.6110 - val_accuracy: 0.8970\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.3286 - accuracy: 0.9296 - val_loss: 0.3912 - val_accuracy: 0.9242\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.1773 - accuracy: 0.9545 - val_loss: 0.3543 - val_accuracy: 0.9322\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.1068 - accuracy: 0.9692 - val_loss: 0.3346 - val_accuracy: 0.9358\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0744 - accuracy: 0.9777 - val_loss: 0.3121 - val_accuracy: 0.9417\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0478 - accuracy: 0.9856 - val_loss: 0.3105 - val_accuracy: 0.9423\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0316 - accuracy: 0.9904 - val_loss: 0.3002 - val_accuracy: 0.9462\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0218 - accuracy: 0.9936 - val_loss: 0.3101 - val_accuracy: 0.9451\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.3148 - val_accuracy: 0.9466\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.3174 - val_accuracy: 0.9464\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.3161 - val_accuracy: 0.9487\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.3160 - val_accuracy: 0.9492\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.3206 - val_accuracy: 0.9490\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.3206 - val_accuracy: 0.9495\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 81us/sample - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.3227 - val_accuracy: 0.9493\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.3235 - val_accuracy: 0.9499\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3256 - val_accuracy: 0.9500\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3275 - val_accuracy: 0.9498\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3300 - val_accuracy: 0.9492\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 81us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3296 - val_accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3315 - val_accuracy: 0.9497\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9506\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3337 - val_accuracy: 0.9496\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 81us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9501\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9508\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 80us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9505\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 9.6177e-04 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9501\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.3442 - accuracy: 0.9503\n",
      "[CV]  learning_rate=0.001509041041403342, n_hidden=2, n_neurons=271, n_softmax=10, total= 1.2min\n",
      "[CV] learning_rate=0.002355088047548626, n_hidden=2, n_neurons=103, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 2.0163 - accuracy: 0.7357 - val_loss: 0.6192 - val_accuracy: 0.8499\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.4878 - accuracy: 0.8729 - val_loss: 0.4455 - val_accuracy: 0.8917\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.3809 - accuracy: 0.9006 - val_loss: 0.4247 - val_accuracy: 0.9004\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.3222 - accuracy: 0.9123 - val_loss: 0.4011 - val_accuracy: 0.9021\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.2870 - accuracy: 0.9210 - val_loss: 0.3651 - val_accuracy: 0.9057\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.2589 - accuracy: 0.9264 - val_loss: 0.3313 - val_accuracy: 0.9143\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.2345 - accuracy: 0.9326 - val_loss: 0.3112 - val_accuracy: 0.9220\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.2187 - accuracy: 0.9361 - val_loss: 0.3324 - val_accuracy: 0.9169\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.2079 - accuracy: 0.9392 - val_loss: 0.3110 - val_accuracy: 0.9230\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1951 - accuracy: 0.9424 - val_loss: 0.3211 - val_accuracy: 0.9210\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1829 - accuracy: 0.9471 - val_loss: 0.2969 - val_accuracy: 0.9258\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1755 - accuracy: 0.9480 - val_loss: 0.3164 - val_accuracy: 0.9239\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1684 - accuracy: 0.9506 - val_loss: 0.2868 - val_accuracy: 0.9312\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1606 - accuracy: 0.9520 - val_loss: 0.2868 - val_accuracy: 0.9301\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1521 - accuracy: 0.9538 - val_loss: 0.3071 - val_accuracy: 0.9233\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1485 - accuracy: 0.9542 - val_loss: 0.2808 - val_accuracy: 0.9311\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1397 - accuracy: 0.9576 - val_loss: 0.2869 - val_accuracy: 0.9298\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1338 - accuracy: 0.9588 - val_loss: 0.2886 - val_accuracy: 0.9302\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1300 - accuracy: 0.9598 - val_loss: 0.2929 - val_accuracy: 0.9277\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1239 - accuracy: 0.9617 - val_loss: 0.2900 - val_accuracy: 0.9333\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1208 - accuracy: 0.9628 - val_loss: 0.2919 - val_accuracy: 0.9314\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1159 - accuracy: 0.9642 - val_loss: 0.2937 - val_accuracy: 0.9289\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1129 - accuracy: 0.9648 - val_loss: 0.2958 - val_accuracy: 0.9314\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1077 - accuracy: 0.9672 - val_loss: 0.3038 - val_accuracy: 0.9308\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.1059 - accuracy: 0.9670 - val_loss: 0.2889 - val_accuracy: 0.9329\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.1022 - accuracy: 0.9684 - val_loss: 0.2896 - val_accuracy: 0.9326\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0989 - accuracy: 0.9698 - val_loss: 0.3008 - val_accuracy: 0.9340\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0995 - accuracy: 0.9692 - val_loss: 0.2880 - val_accuracy: 0.9352\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0920 - accuracy: 0.9709 - val_loss: 0.2974 - val_accuracy: 0.9344\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0894 - accuracy: 0.9726 - val_loss: 0.2921 - val_accuracy: 0.9345\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0886 - accuracy: 0.9722 - val_loss: 0.2998 - val_accuracy: 0.9334\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0849 - accuracy: 0.9738 - val_loss: 0.3145 - val_accuracy: 0.9329\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0819 - accuracy: 0.9752 - val_loss: 0.3203 - val_accuracy: 0.9290\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0826 - accuracy: 0.9747 - val_loss: 0.3083 - val_accuracy: 0.9339\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0821 - accuracy: 0.9743 - val_loss: 0.2960 - val_accuracy: 0.9381\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0782 - accuracy: 0.9755 - val_loss: 0.3025 - val_accuracy: 0.9348\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0751 - accuracy: 0.9767 - val_loss: 0.3214 - val_accuracy: 0.9352\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0731 - accuracy: 0.9770 - val_loss: 0.3073 - val_accuracy: 0.9354\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0730 - accuracy: 0.9771 - val_loss: 0.3203 - val_accuracy: 0.9347\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0722 - accuracy: 0.9774 - val_loss: 0.3201 - val_accuracy: 0.9352\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0684 - accuracy: 0.9789 - val_loss: 0.3235 - val_accuracy: 0.9348\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0664 - accuracy: 0.9791 - val_loss: 0.3132 - val_accuracy: 0.9361\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0666 - accuracy: 0.9800 - val_loss: 0.3211 - val_accuracy: 0.9362\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0617 - accuracy: 0.9810 - val_loss: 0.3382 - val_accuracy: 0.9356\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0615 - accuracy: 0.9811 - val_loss: 0.3465 - val_accuracy: 0.9323\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0624 - accuracy: 0.9807 - val_loss: 0.3417 - val_accuracy: 0.9370\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0585 - accuracy: 0.9818 - val_loss: 0.3506 - val_accuracy: 0.9355\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0593 - accuracy: 0.9809 - val_loss: 0.3500 - val_accuracy: 0.9334\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0568 - accuracy: 0.9820 - val_loss: 0.3477 - val_accuracy: 0.9351\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0575 - accuracy: 0.9813 - val_loss: 0.3487 - val_accuracy: 0.9355\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0548 - accuracy: 0.9822 - val_loss: 0.3523 - val_accuracy: 0.9367\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0556 - accuracy: 0.9827 - val_loss: 0.3653 - val_accuracy: 0.9348\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0521 - accuracy: 0.9833 - val_loss: 0.3498 - val_accuracy: 0.9369\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0514 - accuracy: 0.9850 - val_loss: 0.3549 - val_accuracy: 0.9362\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0496 - accuracy: 0.9843 - val_loss: 0.3490 - val_accuracy: 0.9388\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0484 - accuracy: 0.9853 - val_loss: 0.3636 - val_accuracy: 0.9346\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0486 - accuracy: 0.9850 - val_loss: 0.3596 - val_accuracy: 0.9372\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0463 - accuracy: 0.9857 - val_loss: 0.3712 - val_accuracy: 0.9353\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0470 - accuracy: 0.9856 - val_loss: 0.3605 - val_accuracy: 0.9380\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.3899 - val_accuracy: 0.9358\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0458 - accuracy: 0.9854 - val_loss: 0.3825 - val_accuracy: 0.9385\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0460 - accuracy: 0.9851 - val_loss: 0.3793 - val_accuracy: 0.9377\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0436 - accuracy: 0.9863 - val_loss: 0.3886 - val_accuracy: 0.9377\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0417 - accuracy: 0.9874 - val_loss: 0.3784 - val_accuracy: 0.9360\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0412 - accuracy: 0.9870 - val_loss: 0.3909 - val_accuracy: 0.9358\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.3837 - val_accuracy: 0.9366\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0393 - accuracy: 0.9881 - val_loss: 0.3847 - val_accuracy: 0.9392\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0402 - accuracy: 0.9869 - val_loss: 0.3827 - val_accuracy: 0.9379\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0373 - accuracy: 0.9883 - val_loss: 0.3995 - val_accuracy: 0.9388\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0376 - accuracy: 0.9880 - val_loss: 0.4130 - val_accuracy: 0.9357\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.3891 - val_accuracy: 0.9388\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.4035 - val_accuracy: 0.9389\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0338 - accuracy: 0.9893 - val_loss: 0.4034 - val_accuracy: 0.9370\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0353 - accuracy: 0.9893 - val_loss: 0.4134 - val_accuracy: 0.9374\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.4177 - val_accuracy: 0.9386\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.4050 - val_accuracy: 0.9381\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0315 - accuracy: 0.9903 - val_loss: 0.4356 - val_accuracy: 0.9351\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0350 - accuracy: 0.9886 - val_loss: 0.4278 - val_accuracy: 0.9358\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.4115 - val_accuracy: 0.9411\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0333 - accuracy: 0.9895 - val_loss: 0.4232 - val_accuracy: 0.9383\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0326 - accuracy: 0.9898 - val_loss: 0.4100 - val_accuracy: 0.9409\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0323 - accuracy: 0.9895 - val_loss: 0.4266 - val_accuracy: 0.9377\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0306 - accuracy: 0.9901 - val_loss: 0.4252 - val_accuracy: 0.9384\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0303 - accuracy: 0.9904 - val_loss: 0.4342 - val_accuracy: 0.9409\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0296 - accuracy: 0.9913 - val_loss: 0.4617 - val_accuracy: 0.9355\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.4255 - val_accuracy: 0.9408\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0262 - accuracy: 0.9922 - val_loss: 0.4424 - val_accuracy: 0.9390\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0277 - accuracy: 0.9916 - val_loss: 0.4291 - val_accuracy: 0.9408\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0298 - accuracy: 0.9903 - val_loss: 0.4467 - val_accuracy: 0.9402\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0258 - accuracy: 0.9925 - val_loss: 0.4399 - val_accuracy: 0.9370\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0264 - accuracy: 0.9921 - val_loss: 0.4318 - val_accuracy: 0.9398\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0275 - accuracy: 0.9915 - val_loss: 0.4593 - val_accuracy: 0.9374\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.4560 - val_accuracy: 0.9387\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0242 - accuracy: 0.9920 - val_loss: 0.4619 - val_accuracy: 0.9387\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0254 - accuracy: 0.9924 - val_loss: 0.4509 - val_accuracy: 0.9378\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0248 - accuracy: 0.9922 - val_loss: 0.4586 - val_accuracy: 0.9398\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.4997 - val_accuracy: 0.9354\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.4668 - val_accuracy: 0.9373\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0278 - accuracy: 0.9911 - val_loss: 0.4578 - val_accuracy: 0.9385\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.4620 - val_accuracy: 0.9403\n",
      "16000/16000 [==============================] - 0s 20us/sample - loss: 0.4605 - accuracy: 0.9394\n",
      "[CV]  learning_rate=0.002355088047548626, n_hidden=2, n_neurons=103, n_softmax=20, total= 3.6min\n",
      "[CV] learning_rate=0.002355088047548626, n_hidden=2, n_neurons=103, n_softmax=20 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 1.7302 - accuracy: 0.7487 - val_loss: 0.6415 - val_accuracy: 0.8470\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.4658 - accuracy: 0.8747 - val_loss: 0.4445 - val_accuracy: 0.8875\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.3515 - accuracy: 0.9069 - val_loss: 0.3727 - val_accuracy: 0.9122\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.2864 - accuracy: 0.9208 - val_loss: 0.3550 - val_accuracy: 0.9148\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.2498 - accuracy: 0.9297 - val_loss: 0.3166 - val_accuracy: 0.9195\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.2235 - accuracy: 0.9363 - val_loss: 0.2983 - val_accuracy: 0.9227\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.2008 - accuracy: 0.9420 - val_loss: 0.3047 - val_accuracy: 0.9257\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1825 - accuracy: 0.9469 - val_loss: 0.3123 - val_accuracy: 0.9200\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1706 - accuracy: 0.9505 - val_loss: 0.3009 - val_accuracy: 0.9286\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1592 - accuracy: 0.9523 - val_loss: 0.2820 - val_accuracy: 0.9329\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1479 - accuracy: 0.9558 - val_loss: 0.2793 - val_accuracy: 0.9348\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1393 - accuracy: 0.9581 - val_loss: 0.2794 - val_accuracy: 0.9357\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1292 - accuracy: 0.9612 - val_loss: 0.2898 - val_accuracy: 0.9359\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1240 - accuracy: 0.9638 - val_loss: 0.2750 - val_accuracy: 0.9363\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1155 - accuracy: 0.9649 - val_loss: 0.2837 - val_accuracy: 0.9366\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1094 - accuracy: 0.9672 - val_loss: 0.2734 - val_accuracy: 0.9386\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1051 - accuracy: 0.9691 - val_loss: 0.2776 - val_accuracy: 0.9389\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1024 - accuracy: 0.9689 - val_loss: 0.2761 - val_accuracy: 0.9385\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0939 - accuracy: 0.9715 - val_loss: 0.2841 - val_accuracy: 0.9402\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0932 - accuracy: 0.9713 - val_loss: 0.2770 - val_accuracy: 0.9423\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0879 - accuracy: 0.9728 - val_loss: 0.2750 - val_accuracy: 0.9417\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0836 - accuracy: 0.9749 - val_loss: 0.2769 - val_accuracy: 0.9435\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0812 - accuracy: 0.9747 - val_loss: 0.2859 - val_accuracy: 0.9420\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0768 - accuracy: 0.9758 - val_loss: 0.2969 - val_accuracy: 0.9390\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0743 - accuracy: 0.9777 - val_loss: 0.2807 - val_accuracy: 0.9428\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0707 - accuracy: 0.9782 - val_loss: 0.2891 - val_accuracy: 0.9413\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0679 - accuracy: 0.9795 - val_loss: 0.2944 - val_accuracy: 0.9433\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0643 - accuracy: 0.9805 - val_loss: 0.2981 - val_accuracy: 0.9452\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0618 - accuracy: 0.9808 - val_loss: 0.3010 - val_accuracy: 0.9432\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0617 - accuracy: 0.9809 - val_loss: 0.3051 - val_accuracy: 0.9432\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0574 - accuracy: 0.9821 - val_loss: 0.2977 - val_accuracy: 0.9427\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0577 - accuracy: 0.9826 - val_loss: 0.3131 - val_accuracy: 0.9418\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0540 - accuracy: 0.9831 - val_loss: 0.3107 - val_accuracy: 0.9443\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0519 - accuracy: 0.9843 - val_loss: 0.3061 - val_accuracy: 0.9442\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.3105 - val_accuracy: 0.9452\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0472 - accuracy: 0.9862 - val_loss: 0.3076 - val_accuracy: 0.9451\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0461 - accuracy: 0.9852 - val_loss: 0.3154 - val_accuracy: 0.9444\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0451 - accuracy: 0.9866 - val_loss: 0.3160 - val_accuracy: 0.9441\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0438 - accuracy: 0.9864 - val_loss: 0.3198 - val_accuracy: 0.9435\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0415 - accuracy: 0.9873 - val_loss: 0.3299 - val_accuracy: 0.9442\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.3341 - val_accuracy: 0.9463\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0387 - accuracy: 0.9886 - val_loss: 0.3238 - val_accuracy: 0.9456\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0372 - accuracy: 0.9887 - val_loss: 0.3265 - val_accuracy: 0.9453\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0336 - accuracy: 0.9905 - val_loss: 0.3310 - val_accuracy: 0.9451\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0322 - accuracy: 0.9904 - val_loss: 0.3396 - val_accuracy: 0.9447\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0328 - accuracy: 0.9902 - val_loss: 0.3359 - val_accuracy: 0.9451\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0320 - accuracy: 0.9902 - val_loss: 0.3379 - val_accuracy: 0.9455\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0295 - accuracy: 0.9912 - val_loss: 0.3538 - val_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0305 - accuracy: 0.9912 - val_loss: 0.3544 - val_accuracy: 0.9423\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.3526 - val_accuracy: 0.9454\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0282 - accuracy: 0.9922 - val_loss: 0.3517 - val_accuracy: 0.9453\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.3564 - val_accuracy: 0.9445\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.3725 - val_accuracy: 0.9420\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.3629 - val_accuracy: 0.9469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0237 - accuracy: 0.9934 - val_loss: 0.3701 - val_accuracy: 0.9457\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0246 - accuracy: 0.9933 - val_loss: 0.3690 - val_accuracy: 0.9447\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0246 - accuracy: 0.9929 - val_loss: 0.3710 - val_accuracy: 0.9457\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0240 - accuracy: 0.9926 - val_loss: 0.3722 - val_accuracy: 0.9438\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.3752 - val_accuracy: 0.9456\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.3763 - val_accuracy: 0.9448\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.3877 - val_accuracy: 0.9452\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0196 - accuracy: 0.9944 - val_loss: 0.3815 - val_accuracy: 0.9468\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.3873 - val_accuracy: 0.9451\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.3974 - val_accuracy: 0.9451\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.4180 - val_accuracy: 0.9411\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0177 - accuracy: 0.9946 - val_loss: 0.3949 - val_accuracy: 0.9466\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.3930 - val_accuracy: 0.9457\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.3997 - val_accuracy: 0.9457\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.3966 - val_accuracy: 0.9462\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.4043 - val_accuracy: 0.9457\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0145 - accuracy: 0.9957 - val_loss: 0.4045 - val_accuracy: 0.9459\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0140 - accuracy: 0.9962 - val_loss: 0.4068 - val_accuracy: 0.9452\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0149 - accuracy: 0.9956 - val_loss: 0.4256 - val_accuracy: 0.9446\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0147 - accuracy: 0.9958 - val_loss: 0.4160 - val_accuracy: 0.9455\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0137 - accuracy: 0.9959 - val_loss: 0.4128 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.4177 - val_accuracy: 0.9458\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.4193 - val_accuracy: 0.9452\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0118 - accuracy: 0.9968 - val_loss: 0.4155 - val_accuracy: 0.9462\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0119 - accuracy: 0.9966 - val_loss: 0.4203 - val_accuracy: 0.9449\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0111 - accuracy: 0.9968 - val_loss: 0.4264 - val_accuracy: 0.9442\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.4265 - val_accuracy: 0.9458\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.4300 - val_accuracy: 0.9458\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.4314 - val_accuracy: 0.9459\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.4283 - val_accuracy: 0.9442\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.4392 - val_accuracy: 0.9458\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0097 - accuracy: 0.9972 - val_loss: 0.4361 - val_accuracy: 0.9454\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.4342 - val_accuracy: 0.9460\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 2s 64us/sample - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.4417 - val_accuracy: 0.9457\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.4450 - val_accuracy: 0.9446\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0093 - accuracy: 0.9973 - val_loss: 0.4548 - val_accuracy: 0.9436\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0089 - accuracy: 0.9973 - val_loss: 0.4495 - val_accuracy: 0.9448\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.4510 - val_accuracy: 0.9446\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.4503 - val_accuracy: 0.9450\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0088 - accuracy: 0.9974 - val_loss: 0.4572 - val_accuracy: 0.9453\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.4556 - val_accuracy: 0.9450\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0084 - accuracy: 0.9976 - val_loss: 0.4569 - val_accuracy: 0.9460\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.4561 - val_accuracy: 0.9458\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.4660 - val_accuracy: 0.9457\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.4649 - val_accuracy: 0.9455\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.4664 - val_accuracy: 0.9447\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.4549 - accuracy: 0.9478\n",
      "[CV]  learning_rate=0.002355088047548626, n_hidden=2, n_neurons=103, n_softmax=20, total= 3.5min\n",
      "[CV] learning_rate=0.002355088047548626, n_hidden=2, n_neurons=103, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 3.5498 - accuracy: 0.5769 - val_loss: 1.1507 - val_accuracy: 0.7290\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.9214 - accuracy: 0.7974 - val_loss: 0.8106 - val_accuracy: 0.8357\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.6763 - accuracy: 0.8354 - val_loss: 0.5393 - val_accuracy: 0.8637\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.4915 - accuracy: 0.8716 - val_loss: 0.4571 - val_accuracy: 0.8837\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.3889 - accuracy: 0.8979 - val_loss: 0.4212 - val_accuracy: 0.8992\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.3486 - accuracy: 0.9070 - val_loss: 0.3770 - val_accuracy: 0.9052\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.3164 - accuracy: 0.9132 - val_loss: 0.3914 - val_accuracy: 0.9046\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.2972 - accuracy: 0.9190 - val_loss: 0.3572 - val_accuracy: 0.9126\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.2849 - accuracy: 0.9200 - val_loss: 0.3363 - val_accuracy: 0.9145\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.2662 - accuracy: 0.9250 - val_loss: 0.3310 - val_accuracy: 0.9198\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.2544 - accuracy: 0.9284 - val_loss: 0.3360 - val_accuracy: 0.9188\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.2453 - accuracy: 0.9287 - val_loss: 0.3355 - val_accuracy: 0.9183\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.2377 - accuracy: 0.9324 - val_loss: 0.3305 - val_accuracy: 0.9152\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.2273 - accuracy: 0.9342 - val_loss: 0.3347 - val_accuracy: 0.9195\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.2249 - accuracy: 0.9356 - val_loss: 0.3286 - val_accuracy: 0.9182\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.2167 - accuracy: 0.9381 - val_loss: 0.3245 - val_accuracy: 0.9201\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.2098 - accuracy: 0.9397 - val_loss: 0.3230 - val_accuracy: 0.9233\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.2034 - accuracy: 0.9413 - val_loss: 0.3244 - val_accuracy: 0.9225\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.2034 - accuracy: 0.9401 - val_loss: 0.3297 - val_accuracy: 0.9244\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1970 - accuracy: 0.9433 - val_loss: 0.3104 - val_accuracy: 0.9268\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1907 - accuracy: 0.9448 - val_loss: 0.3197 - val_accuracy: 0.9236\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1895 - accuracy: 0.9441 - val_loss: 0.3178 - val_accuracy: 0.9221\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1840 - accuracy: 0.9454 - val_loss: 0.3183 - val_accuracy: 0.9258\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1834 - accuracy: 0.9458 - val_loss: 0.3145 - val_accuracy: 0.9240\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1819 - accuracy: 0.9464 - val_loss: 0.3126 - val_accuracy: 0.9233\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1764 - accuracy: 0.9478 - val_loss: 0.3093 - val_accuracy: 0.9246\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1724 - accuracy: 0.9490 - val_loss: 0.3094 - val_accuracy: 0.9247\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1707 - accuracy: 0.9490 - val_loss: 0.3206 - val_accuracy: 0.9233\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1679 - accuracy: 0.9492 - val_loss: 0.3172 - val_accuracy: 0.9237\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1661 - accuracy: 0.9501 - val_loss: 0.3037 - val_accuracy: 0.9276\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1623 - accuracy: 0.9522 - val_loss: 0.3312 - val_accuracy: 0.9222\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1615 - accuracy: 0.9520 - val_loss: 0.3184 - val_accuracy: 0.9218\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1578 - accuracy: 0.9520 - val_loss: 0.3045 - val_accuracy: 0.9251\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1567 - accuracy: 0.9533 - val_loss: 0.3067 - val_accuracy: 0.9285\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1570 - accuracy: 0.9530 - val_loss: 0.3043 - val_accuracy: 0.9295\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1501 - accuracy: 0.9557 - val_loss: 0.3292 - val_accuracy: 0.9219\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.1503 - accuracy: 0.9535 - val_loss: 0.3086 - val_accuracy: 0.9283\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1509 - accuracy: 0.9540 - val_loss: 0.3052 - val_accuracy: 0.9289\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1497 - accuracy: 0.9553 - val_loss: 0.3176 - val_accuracy: 0.9273\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1428 - accuracy: 0.9556 - val_loss: 0.3189 - val_accuracy: 0.9258\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1411 - accuracy: 0.9571 - val_loss: 0.3228 - val_accuracy: 0.9271\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1389 - accuracy: 0.9574 - val_loss: 0.3133 - val_accuracy: 0.9293\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1394 - accuracy: 0.9573 - val_loss: 0.3171 - val_accuracy: 0.9288\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1371 - accuracy: 0.9575 - val_loss: 0.3428 - val_accuracy: 0.9238\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1347 - accuracy: 0.9587 - val_loss: 0.3317 - val_accuracy: 0.9253\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1320 - accuracy: 0.9593 - val_loss: 0.3172 - val_accuracy: 0.9277\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1338 - accuracy: 0.9588 - val_loss: 0.3146 - val_accuracy: 0.9301\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1263 - accuracy: 0.9615 - val_loss: 0.3190 - val_accuracy: 0.9288\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1284 - accuracy: 0.9588 - val_loss: 0.3233 - val_accuracy: 0.9247\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1244 - accuracy: 0.9624 - val_loss: 0.3314 - val_accuracy: 0.9280\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1226 - accuracy: 0.9625 - val_loss: 0.3406 - val_accuracy: 0.9255\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1211 - accuracy: 0.9628 - val_loss: 0.3407 - val_accuracy: 0.9298\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1194 - accuracy: 0.9632 - val_loss: 0.3642 - val_accuracy: 0.9209\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1168 - accuracy: 0.9642 - val_loss: 0.3478 - val_accuracy: 0.9281\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1149 - accuracy: 0.9640 - val_loss: 0.3340 - val_accuracy: 0.9297\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.1153 - accuracy: 0.9643 - val_loss: 0.3439 - val_accuracy: 0.9299\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1132 - accuracy: 0.9648 - val_loss: 0.3431 - val_accuracy: 0.9285\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1148 - accuracy: 0.9649 - val_loss: 0.3320 - val_accuracy: 0.9286\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1081 - accuracy: 0.9666 - val_loss: 0.3365 - val_accuracy: 0.9308\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1103 - accuracy: 0.9654 - val_loss: 0.3243 - val_accuracy: 0.9298\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1093 - accuracy: 0.9670 - val_loss: 0.3464 - val_accuracy: 0.9287\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1059 - accuracy: 0.9680 - val_loss: 0.3617 - val_accuracy: 0.9251\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1060 - accuracy: 0.9673 - val_loss: 0.3561 - val_accuracy: 0.9287\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1042 - accuracy: 0.9682 - val_loss: 0.3636 - val_accuracy: 0.9277\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1054 - accuracy: 0.9673 - val_loss: 0.3660 - val_accuracy: 0.9277\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1017 - accuracy: 0.9684 - val_loss: 0.3558 - val_accuracy: 0.9295\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.1012 - accuracy: 0.9684 - val_loss: 0.3686 - val_accuracy: 0.9302\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.1016 - accuracy: 0.9688 - val_loss: 0.3533 - val_accuracy: 0.9300\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0977 - accuracy: 0.9700 - val_loss: 0.3603 - val_accuracy: 0.9278\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0962 - accuracy: 0.9700 - val_loss: 0.3646 - val_accuracy: 0.9293\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0988 - accuracy: 0.9694 - val_loss: 0.3733 - val_accuracy: 0.9285\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0977 - accuracy: 0.9701 - val_loss: 0.3767 - val_accuracy: 0.9264\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0960 - accuracy: 0.9703 - val_loss: 0.3667 - val_accuracy: 0.9283\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0954 - accuracy: 0.9707 - val_loss: 0.3939 - val_accuracy: 0.9250\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0951 - accuracy: 0.9704 - val_loss: 0.3583 - val_accuracy: 0.9317\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0924 - accuracy: 0.9712 - val_loss: 0.3707 - val_accuracy: 0.9301\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0924 - accuracy: 0.9721 - val_loss: 0.3752 - val_accuracy: 0.9281\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0924 - accuracy: 0.9713 - val_loss: 0.3844 - val_accuracy: 0.9279\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0901 - accuracy: 0.9729 - val_loss: 0.3801 - val_accuracy: 0.9270\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0884 - accuracy: 0.9726 - val_loss: 0.3859 - val_accuracy: 0.9257\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0910 - accuracy: 0.9720 - val_loss: 0.3754 - val_accuracy: 0.9305\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0861 - accuracy: 0.9737 - val_loss: 0.3828 - val_accuracy: 0.9275\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0862 - accuracy: 0.9737 - val_loss: 0.3829 - val_accuracy: 0.9272\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0859 - accuracy: 0.9734 - val_loss: 0.3764 - val_accuracy: 0.9300\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0878 - accuracy: 0.9727 - val_loss: 0.3963 - val_accuracy: 0.9268\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0861 - accuracy: 0.9731 - val_loss: 0.3946 - val_accuracy: 0.9258\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0867 - accuracy: 0.9725 - val_loss: 0.3870 - val_accuracy: 0.9273\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0827 - accuracy: 0.9745 - val_loss: 0.3926 - val_accuracy: 0.9273\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0826 - accuracy: 0.9748 - val_loss: 0.3968 - val_accuracy: 0.9251\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0831 - accuracy: 0.9747 - val_loss: 0.4115 - val_accuracy: 0.9258\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0813 - accuracy: 0.9754 - val_loss: 0.3998 - val_accuracy: 0.9285\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0836 - accuracy: 0.9744 - val_loss: 0.3853 - val_accuracy: 0.9297\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0806 - accuracy: 0.9747 - val_loss: 0.3927 - val_accuracy: 0.9288\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0805 - accuracy: 0.9755 - val_loss: 0.4248 - val_accuracy: 0.9257\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0784 - accuracy: 0.9759 - val_loss: 0.3926 - val_accuracy: 0.9283\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0772 - accuracy: 0.9759 - val_loss: 0.3983 - val_accuracy: 0.9288\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0773 - accuracy: 0.9753 - val_loss: 0.4182 - val_accuracy: 0.9263\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0804 - accuracy: 0.9756 - val_loss: 0.4078 - val_accuracy: 0.9273\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 2s 65us/sample - loss: 0.0792 - accuracy: 0.9766 - val_loss: 0.4012 - val_accuracy: 0.9293\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0762 - accuracy: 0.9766 - val_loss: 0.4249 - val_accuracy: 0.9273\n",
      "16000/16000 [==============================] - 0s 21us/sample - loss: 0.3891 - accuracy: 0.9281\n",
      "[CV]  learning_rate=0.002355088047548626, n_hidden=2, n_neurons=103, n_softmax=20, total= 3.5min\n",
      "[CV] learning_rate=0.00118693873027787, n_hidden=4, n_neurons=459, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 6s 196us/sample - loss: 1.1656 - accuracy: 0.8585 - val_loss: 0.3362 - val_accuracy: 0.9114\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 6s 186us/sample - loss: 0.1698 - accuracy: 0.9504 - val_loss: 0.2920 - val_accuracy: 0.9255\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0784 - accuracy: 0.9748 - val_loss: 0.2455 - val_accuracy: 0.9396\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 6s 184us/sample - loss: 0.0364 - accuracy: 0.9905 - val_loss: 0.2409 - val_accuracy: 0.9432\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 6s 187us/sample - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.2409 - val_accuracy: 0.9454\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0079 - accuracy: 0.9993 - val_loss: 0.2383 - val_accuracy: 0.9472\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 6s 187us/sample - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.2400 - val_accuracy: 0.9472\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 6s 183us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2412 - val_accuracy: 0.9478\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 6s 181us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9488\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 6s 186us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9492\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 6s 181us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9492\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 6s 180us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2450 - val_accuracy: 0.9494\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 6s 183us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9501\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 6s 179us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2466 - val_accuracy: 0.9513\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 6s 179us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2478 - val_accuracy: 0.9502\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2479 - val_accuracy: 0.9510\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 6s 178us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 0.9508\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9511\n",
      "16000/16000 [==============================] - 2s 98us/sample - loss: 0.2434 - accuracy: 0.9496\n",
      "[CV]  learning_rate=0.00118693873027787, n_hidden=4, n_neurons=459, n_softmax=20, total= 1.8min\n",
      "[CV] learning_rate=0.00118693873027787, n_hidden=4, n_neurons=459, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 6s 191us/sample - loss: 1.1260 - accuracy: 0.8574 - val_loss: 0.3406 - val_accuracy: 0.9114\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 6s 176us/sample - loss: 0.1845 - accuracy: 0.9471 - val_loss: 0.2518 - val_accuracy: 0.9321\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 6s 180us/sample - loss: 0.0831 - accuracy: 0.9753 - val_loss: 0.2331 - val_accuracy: 0.9413\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 6s 177us/sample - loss: 0.0401 - accuracy: 0.9883 - val_loss: 0.2203 - val_accuracy: 0.9446\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 6s 180us/sample - loss: 0.0180 - accuracy: 0.9962 - val_loss: 0.2119 - val_accuracy: 0.9490\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 6s 184us/sample - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.2100 - val_accuracy: 0.9498\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 6s 181us/sample - loss: 0.0053 - accuracy: 0.9998 - val_loss: 0.2118 - val_accuracy: 0.9513\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 6s 187us/sample - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.2125 - val_accuracy: 0.9516\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 6s 186us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2141 - val_accuracy: 0.9518\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 6s 185us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.2149 - val_accuracy: 0.9522\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 6s 186us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2156 - val_accuracy: 0.9525\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 6s 181us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2163 - val_accuracy: 0.9527\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 6s 180us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2172 - val_accuracy: 0.9528\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2180 - val_accuracy: 0.9528\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 6s 179us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2183 - val_accuracy: 0.9528\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 6s 180us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9525\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 6s 183us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9527\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 6s 180us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2200 - val_accuracy: 0.9527\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 6s 185us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9535\n",
      "16000/16000 [==============================] - 2s 96us/sample - loss: 0.2258 - accuracy: 0.9534\n",
      "[CV]  learning_rate=0.00118693873027787, n_hidden=4, n_neurons=459, n_softmax=20, total= 1.9min\n",
      "[CV] learning_rate=0.00118693873027787, n_hidden=4, n_neurons=459, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 6s 192us/sample - loss: 1.0668 - accuracy: 0.8621 - val_loss: 0.3827 - val_accuracy: 0.9115\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 6s 178us/sample - loss: 0.1796 - accuracy: 0.9500 - val_loss: 0.2967 - val_accuracy: 0.9280\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0834 - accuracy: 0.9750 - val_loss: 0.2542 - val_accuracy: 0.9383\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 6s 177us/sample - loss: 0.0340 - accuracy: 0.9902 - val_loss: 0.2388 - val_accuracy: 0.9423\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 6s 179us/sample - loss: 0.0135 - accuracy: 0.9976 - val_loss: 0.2367 - val_accuracy: 0.9452\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 6s 181us/sample - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.2335 - val_accuracy: 0.9463\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 6s 178us/sample - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.2356 - val_accuracy: 0.9481\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2363 - val_accuracy: 0.9489\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 6s 179us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.2384 - val_accuracy: 0.9489\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 7s 216us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2392 - val_accuracy: 0.9493\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2400 - val_accuracy: 0.9492\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 6s 177us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2408 - val_accuracy: 0.9495\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 6s 178us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2417 - val_accuracy: 0.9498\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 6s 180us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2425 - val_accuracy: 0.9502\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 6s 177us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2431 - val_accuracy: 0.9501\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 6s 182us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9506\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 6s 181us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 0.9509\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 6s 178us/sample - loss: 9.5889e-04 - accuracy: 1.0000 - val_loss: 0.2446 - val_accuracy: 0.9509\n",
      "16000/16000 [==============================] - 2s 95us/sample - loss: 0.2342 - accuracy: 0.9527\n",
      "[CV]  learning_rate=0.00118693873027787, n_hidden=4, n_neurons=459, n_softmax=20, total= 1.8min\n",
      "[CV] learning_rate=0.0014428443104887705, n_hidden=4, n_neurons=150, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 102us/sample - loss: 0.9988 - accuracy: 0.8224 - val_loss: 0.4067 - val_accuracy: 0.8911\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.2744 - accuracy: 0.9201 - val_loss: 0.3125 - val_accuracy: 0.9168\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.1859 - accuracy: 0.9429 - val_loss: 0.2880 - val_accuracy: 0.9240\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.1363 - accuracy: 0.9577 - val_loss: 0.2523 - val_accuracy: 0.9342\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.1030 - accuracy: 0.9682 - val_loss: 0.2695 - val_accuracy: 0.9331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0806 - accuracy: 0.9752 - val_loss: 0.2442 - val_accuracy: 0.9363\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0632 - accuracy: 0.9810 - val_loss: 0.2392 - val_accuracy: 0.9402\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0506 - accuracy: 0.9856 - val_loss: 0.2509 - val_accuracy: 0.9383\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0389 - accuracy: 0.9897 - val_loss: 0.2371 - val_accuracy: 0.9442\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0311 - accuracy: 0.9923 - val_loss: 0.2407 - val_accuracy: 0.9439\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0254 - accuracy: 0.9939 - val_loss: 0.2386 - val_accuracy: 0.9458\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0202 - accuracy: 0.9957 - val_loss: 0.2393 - val_accuracy: 0.9453\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.2415 - val_accuracy: 0.9467\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0129 - accuracy: 0.9982 - val_loss: 0.2418 - val_accuracy: 0.9478\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0106 - accuracy: 0.9987 - val_loss: 0.2462 - val_accuracy: 0.9477\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.2460 - val_accuracy: 0.9488\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.2485 - val_accuracy: 0.9473\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0062 - accuracy: 0.9997 - val_loss: 0.2517 - val_accuracy: 0.9485\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.2512 - val_accuracy: 0.9485\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.2532 - val_accuracy: 0.9503\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.2559 - val_accuracy: 0.9502\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.2557 - val_accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.2570 - val_accuracy: 0.9503\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.2593 - val_accuracy: 0.9502\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2607 - val_accuracy: 0.9504\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2625 - val_accuracy: 0.9503\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 0.9513\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2653 - val_accuracy: 0.9512\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2655 - val_accuracy: 0.9511\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9510\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2678 - val_accuracy: 0.9511\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2693 - val_accuracy: 0.9514\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2703 - val_accuracy: 0.9510\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2719 - val_accuracy: 0.9509\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2720 - val_accuracy: 0.9515\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.2685 - accuracy: 0.9514\n",
      "[CV]  learning_rate=0.0014428443104887705, n_hidden=4, n_neurons=150, n_softmax=10, total= 1.7min\n",
      "[CV] learning_rate=0.0014428443104887705, n_hidden=4, n_neurons=150, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 1.0595 - accuracy: 0.8102 - val_loss: 0.4149 - val_accuracy: 0.8818\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.2930 - accuracy: 0.9122 - val_loss: 0.3151 - val_accuracy: 0.9112\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.2066 - accuracy: 0.9377 - val_loss: 0.2795 - val_accuracy: 0.9230\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.1579 - accuracy: 0.9510 - val_loss: 0.2615 - val_accuracy: 0.9261\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.1253 - accuracy: 0.9611 - val_loss: 0.2483 - val_accuracy: 0.9322\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.1016 - accuracy: 0.9691 - val_loss: 0.2392 - val_accuracy: 0.9337\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0833 - accuracy: 0.9750 - val_loss: 0.2437 - val_accuracy: 0.9389\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0690 - accuracy: 0.9801 - val_loss: 0.2377 - val_accuracy: 0.9388\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0574 - accuracy: 0.9828 - val_loss: 0.2387 - val_accuracy: 0.9415\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0475 - accuracy: 0.9865 - val_loss: 0.2371 - val_accuracy: 0.9423\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0400 - accuracy: 0.9891 - val_loss: 0.2355 - val_accuracy: 0.9437\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0335 - accuracy: 0.9916 - val_loss: 0.2353 - val_accuracy: 0.9446\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0276 - accuracy: 0.9936 - val_loss: 0.2414 - val_accuracy: 0.9437\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0232 - accuracy: 0.9950 - val_loss: 0.2383 - val_accuracy: 0.9456\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0193 - accuracy: 0.9963 - val_loss: 0.2473 - val_accuracy: 0.9463\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0160 - accuracy: 0.9975 - val_loss: 0.2462 - val_accuracy: 0.9473\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0132 - accuracy: 0.9981 - val_loss: 0.2499 - val_accuracy: 0.9482\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0115 - accuracy: 0.9988 - val_loss: 0.2506 - val_accuracy: 0.9478\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0098 - accuracy: 0.9992 - val_loss: 0.2532 - val_accuracy: 0.9479\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0085 - accuracy: 0.9991 - val_loss: 0.2558 - val_accuracy: 0.9487\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0072 - accuracy: 0.9995 - val_loss: 0.2595 - val_accuracy: 0.9482\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0064 - accuracy: 0.9995 - val_loss: 0.2623 - val_accuracy: 0.9482\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.2651 - val_accuracy: 0.9475\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.2664 - val_accuracy: 0.9492\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.2689 - val_accuracy: 0.9488\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.2719 - val_accuracy: 0.9488\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.2720 - val_accuracy: 0.9501\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.2750 - val_accuracy: 0.9494\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.2788 - val_accuracy: 0.9491\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.2803 - val_accuracy: 0.9495\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.2812 - val_accuracy: 0.9498\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9490\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2843 - val_accuracy: 0.9490\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9498\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2862 - val_accuracy: 0.9499\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2882 - val_accuracy: 0.9497\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2900 - val_accuracy: 0.9499\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9503\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 0.9502\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2932 - val_accuracy: 0.9503\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2940 - val_accuracy: 0.9507\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2954 - val_accuracy: 0.9502\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2970 - val_accuracy: 0.9503\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2602 - accuracy: 0.9542\n",
      "[CV]  learning_rate=0.0014428443104887705, n_hidden=4, n_neurons=150, n_softmax=10, total= 2.1min\n",
      "[CV] learning_rate=0.0014428443104887705, n_hidden=4, n_neurons=150, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 102us/sample - loss: 0.9963 - accuracy: 0.8122 - val_loss: 0.3981 - val_accuracy: 0.8882\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.2828 - accuracy: 0.9179 - val_loss: 0.3182 - val_accuracy: 0.9105\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.2031 - accuracy: 0.9388 - val_loss: 0.2695 - val_accuracy: 0.9248\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.1546 - accuracy: 0.9515 - val_loss: 0.2609 - val_accuracy: 0.9287\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.1251 - accuracy: 0.9604 - val_loss: 0.2498 - val_accuracy: 0.9331\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.1014 - accuracy: 0.9689 - val_loss: 0.2491 - val_accuracy: 0.9338\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0828 - accuracy: 0.9748 - val_loss: 0.2384 - val_accuracy: 0.9381\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0699 - accuracy: 0.9791 - val_loss: 0.2425 - val_accuracy: 0.9377\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0575 - accuracy: 0.9830 - val_loss: 0.2426 - val_accuracy: 0.9410\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0483 - accuracy: 0.9872 - val_loss: 0.2375 - val_accuracy: 0.9438\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0399 - accuracy: 0.9894 - val_loss: 0.2381 - val_accuracy: 0.9424\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.0340 - accuracy: 0.9908 - val_loss: 0.2508 - val_accuracy: 0.9396\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0285 - accuracy: 0.9933 - val_loss: 0.2404 - val_accuracy: 0.9448\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0241 - accuracy: 0.9943 - val_loss: 0.2441 - val_accuracy: 0.9440\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0203 - accuracy: 0.9959 - val_loss: 0.2489 - val_accuracy: 0.9457\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0171 - accuracy: 0.9968 - val_loss: 0.2698 - val_accuracy: 0.9419\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.2476 - val_accuracy: 0.9465\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0129 - accuracy: 0.9980 - val_loss: 0.2520 - val_accuracy: 0.9456\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0107 - accuracy: 0.9986 - val_loss: 0.2549 - val_accuracy: 0.9464\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0091 - accuracy: 0.9990 - val_loss: 0.2555 - val_accuracy: 0.9474\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0081 - accuracy: 0.9991 - val_loss: 0.2618 - val_accuracy: 0.9454\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0071 - accuracy: 0.9995 - val_loss: 0.2568 - val_accuracy: 0.9482\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.2662 - val_accuracy: 0.9470\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.2657 - val_accuracy: 0.9474\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.2687 - val_accuracy: 0.9477\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0043 - accuracy: 0.9998 - val_loss: 0.2718 - val_accuracy: 0.9471\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 94us/sample - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.2721 - val_accuracy: 0.9477\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.2748 - val_accuracy: 0.9467\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.2777 - val_accuracy: 0.9479\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.2791 - val_accuracy: 0.9473\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9463\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9477\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2848 - val_accuracy: 0.9473\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2858 - val_accuracy: 0.9481\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2888 - val_accuracy: 0.9477\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2903 - val_accuracy: 0.9477\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2916 - val_accuracy: 0.9479\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9482\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2920 - val_accuracy: 0.9486\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2952 - val_accuracy: 0.9480\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2959 - val_accuracy: 0.9480\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2957 - val_accuracy: 0.9485\n",
      "16000/16000 [==============================] - 0s 29us/sample - loss: 0.2774 - accuracy: 0.9511\n",
      "[CV]  learning_rate=0.0014428443104887705, n_hidden=4, n_neurons=150, n_softmax=10, total= 2.1min\n",
      "[CV] learning_rate=0.0029024490554638606, n_hidden=3, n_neurons=294, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 4s 110us/sample - loss: 2.5202 - accuracy: 0.8312 - val_loss: 0.3305 - val_accuracy: 0.9067\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.2343 - accuracy: 0.9296 - val_loss: 0.2596 - val_accuracy: 0.9275\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.1535 - accuracy: 0.9538 - val_loss: 0.2260 - val_accuracy: 0.9377\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.1099 - accuracy: 0.9666 - val_loss: 0.2073 - val_accuracy: 0.9440\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0813 - accuracy: 0.9748 - val_loss: 0.2081 - val_accuracy: 0.9485\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0607 - accuracy: 0.9828 - val_loss: 0.1976 - val_accuracy: 0.9499\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 103us/sample - loss: 0.0460 - accuracy: 0.9868 - val_loss: 0.2007 - val_accuracy: 0.9517\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0350 - accuracy: 0.9895 - val_loss: 0.2134 - val_accuracy: 0.9488\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0261 - accuracy: 0.9930 - val_loss: 0.2092 - val_accuracy: 0.9542\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.2050 - val_accuracy: 0.9542\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.2021 - val_accuracy: 0.9551\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.2140 - val_accuracy: 0.9564\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.2151 - val_accuracy: 0.9560\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.2148 - val_accuracy: 0.9572\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.2156 - val_accuracy: 0.9578\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.2214 - val_accuracy: 0.9572\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 103us/sample - loss: 0.0027 - accuracy: 0.9999 - val_loss: 0.2237 - val_accuracy: 0.9585\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2260 - val_accuracy: 0.9585\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2263 - val_accuracy: 0.9583\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.2302 - val_accuracy: 0.9583\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2323 - val_accuracy: 0.9581\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 103us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2346 - val_accuracy: 0.9583\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2348 - val_accuracy: 0.9578\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2366 - val_accuracy: 0.9582\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 102us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2382 - val_accuracy: 0.9587\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 9.7836e-04 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9586\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 103us/sample - loss: 9.1904e-04 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9582\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 8.7135e-04 - accuracy: 1.0000 - val_loss: 0.2433 - val_accuracy: 0.9583\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 8.1733e-04 - accuracy: 1.0000 - val_loss: 0.2436 - val_accuracy: 0.9586\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 4s 110us/sample - loss: 7.7568e-04 - accuracy: 1.0000 - val_loss: 0.2445 - val_accuracy: 0.9584\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 7.3205e-04 - accuracy: 1.0000 - val_loss: 0.2452 - val_accuracy: 0.9586\n",
      "16000/16000 [==============================] - 1s 51us/sample - loss: 0.2541 - accuracy: 0.9557\n",
      "[CV]  learning_rate=0.0029024490554638606, n_hidden=3, n_neurons=294, n_softmax=20, total= 1.7min\n",
      "[CV] learning_rate=0.0029024490554638606, n_hidden=3, n_neurons=294, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 4s 117us/sample - loss: 2.0175 - accuracy: 0.8362 - val_loss: 0.3419 - val_accuracy: 0.9007\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.2385 - accuracy: 0.9291 - val_loss: 0.2664 - val_accuracy: 0.9226\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.1665 - accuracy: 0.9502 - val_loss: 0.2341 - val_accuracy: 0.9356\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.1211 - accuracy: 0.9616 - val_loss: 0.2194 - val_accuracy: 0.9413\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 102us/sample - loss: 0.0939 - accuracy: 0.9711 - val_loss: 0.2168 - val_accuracy: 0.9458\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.0751 - accuracy: 0.9765 - val_loss: 0.2256 - val_accuracy: 0.9442\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0572 - accuracy: 0.9823 - val_loss: 0.1992 - val_accuracy: 0.9515\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0452 - accuracy: 0.9860 - val_loss: 0.2153 - val_accuracy: 0.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0347 - accuracy: 0.9898 - val_loss: 0.2072 - val_accuracy: 0.9538\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 103us/sample - loss: 0.0281 - accuracy: 0.9921 - val_loss: 0.2096 - val_accuracy: 0.9540\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.0216 - accuracy: 0.9943 - val_loss: 0.2142 - val_accuracy: 0.9534\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0169 - accuracy: 0.9957 - val_loss: 0.2185 - val_accuracy: 0.9532\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.2196 - val_accuracy: 0.9544\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 97us/sample - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.2231 - val_accuracy: 0.9544\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.2288 - val_accuracy: 0.9560\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.2328 - val_accuracy: 0.9563\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0037 - accuracy: 0.9997 - val_loss: 0.2305 - val_accuracy: 0.9573\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.2344 - val_accuracy: 0.9568\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.2362 - val_accuracy: 0.9572\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2376 - val_accuracy: 0.9575\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2391 - val_accuracy: 0.9568\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2427 - val_accuracy: 0.9575\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9577\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2461 - val_accuracy: 0.9568\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2471 - val_accuracy: 0.9573\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2484 - val_accuracy: 0.9572\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 9.6388e-04 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9576\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 8.9234e-04 - accuracy: 1.0000 - val_loss: 0.2509 - val_accuracy: 0.9582\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 8.3617e-04 - accuracy: 1.0000 - val_loss: 0.2529 - val_accuracy: 0.9580\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 7.9069e-04 - accuracy: 1.0000 - val_loss: 0.2533 - val_accuracy: 0.9578\n",
      "16000/16000 [==============================] - 1s 50us/sample - loss: 0.2481 - accuracy: 0.9602\n",
      "[CV]  learning_rate=0.0029024490554638606, n_hidden=3, n_neurons=294, n_softmax=20, total= 1.6min\n",
      "[CV] learning_rate=0.0029024490554638606, n_hidden=3, n_neurons=294, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 4s 113us/sample - loss: 2.8772 - accuracy: 0.8123 - val_loss: 0.3560 - val_accuracy: 0.8977\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.2654 - accuracy: 0.9212 - val_loss: 0.2822 - val_accuracy: 0.9165\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.1977 - accuracy: 0.9392 - val_loss: 0.2467 - val_accuracy: 0.9299\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.1562 - accuracy: 0.9502 - val_loss: 0.2294 - val_accuracy: 0.9358\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 103us/sample - loss: 0.1321 - accuracy: 0.9584 - val_loss: 0.2303 - val_accuracy: 0.9371\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.1123 - accuracy: 0.9648 - val_loss: 0.2121 - val_accuracy: 0.9441\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0936 - accuracy: 0.9702 - val_loss: 0.2019 - val_accuracy: 0.9459\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0801 - accuracy: 0.9748 - val_loss: 0.2136 - val_accuracy: 0.9447\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0702 - accuracy: 0.9780 - val_loss: 0.2103 - val_accuracy: 0.9472\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 4s 112us/sample - loss: 0.0583 - accuracy: 0.9817 - val_loss: 0.2097 - val_accuracy: 0.9493\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 103us/sample - loss: 0.0511 - accuracy: 0.9839 - val_loss: 0.2158 - val_accuracy: 0.9489\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 105us/sample - loss: 0.0458 - accuracy: 0.9853 - val_loss: 0.2291 - val_accuracy: 0.9477\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0388 - accuracy: 0.9876 - val_loss: 0.2159 - val_accuracy: 0.9496\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0315 - accuracy: 0.9907 - val_loss: 0.2399 - val_accuracy: 0.9493\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 104us/sample - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.2318 - val_accuracy: 0.9495\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.2509 - val_accuracy: 0.9473\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0205 - accuracy: 0.9943 - val_loss: 0.2262 - val_accuracy: 0.9523\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.2329 - val_accuracy: 0.9524\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.2423 - val_accuracy: 0.9521\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 0.0134 - accuracy: 0.9967 - val_loss: 0.2411 - val_accuracy: 0.9542\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.2472 - val_accuracy: 0.9535\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0070 - accuracy: 0.9991 - val_loss: 0.2494 - val_accuracy: 0.9542\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.2530 - val_accuracy: 0.9526\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.2542 - val_accuracy: 0.9535\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 102us/sample - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.2563 - val_accuracy: 0.9541\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.2637 - val_accuracy: 0.9542\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.2621 - val_accuracy: 0.9552\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.2679 - val_accuracy: 0.9544\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.2682 - val_accuracy: 0.9544\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 102us/sample - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.2698 - val_accuracy: 0.9557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.2741 - val_accuracy: 0.9551\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.2747 - val_accuracy: 0.9548\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.2765 - val_accuracy: 0.9552\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 3s 98us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.2786 - val_accuracy: 0.9557\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 3s 102us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.2779 - val_accuracy: 0.9557\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2808 - val_accuracy: 0.9548\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9554\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2834 - val_accuracy: 0.9555\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9556\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 3s 101us/sample - loss: 9.4800e-04 - accuracy: 1.0000 - val_loss: 0.2865 - val_accuracy: 0.9557\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 9.5463e-04 - accuracy: 1.0000 - val_loss: 0.2885 - val_accuracy: 0.9553\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 8.5808e-04 - accuracy: 1.0000 - val_loss: 0.2889 - val_accuracy: 0.9553\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 8.3759e-04 - accuracy: 1.0000 - val_loss: 0.2893 - val_accuracy: 0.9554\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 7.8123e-04 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 0.9556\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 3s 102us/sample - loss: 7.5179e-04 - accuracy: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9560\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 7.1706e-04 - accuracy: 1.0000 - val_loss: 0.2937 - val_accuracy: 0.9560\n",
      "16000/16000 [==============================] - 1s 53us/sample - loss: 0.3009 - accuracy: 0.9546\n",
      "[CV]  learning_rate=0.0029024490554638606, n_hidden=3, n_neurons=294, n_softmax=20, total= 2.5min\n",
      "[CV] learning_rate=0.0012211037261966795, n_hidden=2, n_neurons=161, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 1.9459 - accuracy: 0.8278 - val_loss: 0.6480 - val_accuracy: 0.8725\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.4081 - accuracy: 0.9091 - val_loss: 0.4840 - val_accuracy: 0.9068\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.2537 - accuracy: 0.9348 - val_loss: 0.3976 - val_accuracy: 0.9172\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.1757 - accuracy: 0.9508 - val_loss: 0.4012 - val_accuracy: 0.9208\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.1353 - accuracy: 0.9611 - val_loss: 0.3996 - val_accuracy: 0.9212\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.1043 - accuracy: 0.9683 - val_loss: 0.3831 - val_accuracy: 0.9258\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0842 - accuracy: 0.9737 - val_loss: 0.3770 - val_accuracy: 0.9265\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0673 - accuracy: 0.9793 - val_loss: 0.3745 - val_accuracy: 0.9294\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0552 - accuracy: 0.9827 - val_loss: 0.3706 - val_accuracy: 0.9331\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0462 - accuracy: 0.9862 - val_loss: 0.3733 - val_accuracy: 0.9334\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0385 - accuracy: 0.9883 - val_loss: 0.3881 - val_accuracy: 0.9314\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0322 - accuracy: 0.9904 - val_loss: 0.3853 - val_accuracy: 0.9331\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0267 - accuracy: 0.9931 - val_loss: 0.3877 - val_accuracy: 0.9345\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0224 - accuracy: 0.9941 - val_loss: 0.3911 - val_accuracy: 0.9344\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0195 - accuracy: 0.9952 - val_loss: 0.3911 - val_accuracy: 0.9345\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0170 - accuracy: 0.9964 - val_loss: 0.3889 - val_accuracy: 0.9361\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0144 - accuracy: 0.9973 - val_loss: 0.3938 - val_accuracy: 0.9366\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.4030 - val_accuracy: 0.9363\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0110 - accuracy: 0.9981 - val_loss: 0.4030 - val_accuracy: 0.9352\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0096 - accuracy: 0.9986 - val_loss: 0.4034 - val_accuracy: 0.9362\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.4027 - val_accuracy: 0.9369\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0078 - accuracy: 0.9990 - val_loss: 0.4056 - val_accuracy: 0.9373\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0071 - accuracy: 0.9990 - val_loss: 0.4110 - val_accuracy: 0.9380\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.4149 - val_accuracy: 0.9371\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.4198 - val_accuracy: 0.9367\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.4167 - val_accuracy: 0.9378\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.4195 - val_accuracy: 0.9383\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.4181 - val_accuracy: 0.9392\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.4205 - val_accuracy: 0.9390\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.4239 - val_accuracy: 0.9392\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.4222 - val_accuracy: 0.9401\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4258 - val_accuracy: 0.9390\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.4270 - val_accuracy: 0.9400\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.4288 - val_accuracy: 0.9391\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.4300 - val_accuracy: 0.9392\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.4310 - val_accuracy: 0.9396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.4311 - val_accuracy: 0.9402\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.4346 - val_accuracy: 0.9399\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.4347 - val_accuracy: 0.9398\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.4363 - val_accuracy: 0.9397\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.4387 - val_accuracy: 0.9401\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.4380 - val_accuracy: 0.9403\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.4412 - val_accuracy: 0.9401\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.4409 - val_accuracy: 0.9401\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.4437 - val_accuracy: 0.9404\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.4448 - val_accuracy: 0.9408\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0019 - accuracy: 0.9999 - val_loss: 0.4440 - val_accuracy: 0.9410\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.4450 - val_accuracy: 0.9408\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.4473 - val_accuracy: 0.9408\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.4473 - val_accuracy: 0.9408\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.4479 - val_accuracy: 0.9402\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.4323 - accuracy: 0.9411\n",
      "[CV]  learning_rate=0.0012211037261966795, n_hidden=2, n_neurons=161, n_softmax=20, total= 1.9min\n",
      "[CV] learning_rate=0.0012211037261966795, n_hidden=2, n_neurons=161, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 1.8723 - accuracy: 0.8238 - val_loss: 0.6048 - val_accuracy: 0.8790\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.4113 - accuracy: 0.9018 - val_loss: 0.4729 - val_accuracy: 0.8949\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.2685 - accuracy: 0.9277 - val_loss: 0.3947 - val_accuracy: 0.9139\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 72us/sample - loss: 0.1938 - accuracy: 0.9448 - val_loss: 0.3754 - val_accuracy: 0.9242\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.1505 - accuracy: 0.9562 - val_loss: 0.3606 - val_accuracy: 0.9259\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.1239 - accuracy: 0.9625 - val_loss: 0.3523 - val_accuracy: 0.9293\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0965 - accuracy: 0.9702 - val_loss: 0.3389 - val_accuracy: 0.9314\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0843 - accuracy: 0.9737 - val_loss: 0.3326 - val_accuracy: 0.9357\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0685 - accuracy: 0.9793 - val_loss: 0.3436 - val_accuracy: 0.9339\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0597 - accuracy: 0.9812 - val_loss: 0.3349 - val_accuracy: 0.9364\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.3383 - val_accuracy: 0.9376\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0434 - accuracy: 0.9870 - val_loss: 0.3415 - val_accuracy: 0.9377\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0378 - accuracy: 0.9890 - val_loss: 0.3405 - val_accuracy: 0.9388\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0329 - accuracy: 0.9908 - val_loss: 0.3366 - val_accuracy: 0.9428\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0285 - accuracy: 0.9923 - val_loss: 0.3453 - val_accuracy: 0.9407\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0254 - accuracy: 0.9933 - val_loss: 0.3450 - val_accuracy: 0.9419\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0222 - accuracy: 0.9945 - val_loss: 0.3446 - val_accuracy: 0.9434\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0204 - accuracy: 0.9950 - val_loss: 0.3492 - val_accuracy: 0.9417\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0177 - accuracy: 0.9958 - val_loss: 0.3504 - val_accuracy: 0.9432\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0162 - accuracy: 0.9965 - val_loss: 0.3524 - val_accuracy: 0.9435\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0143 - accuracy: 0.9970 - val_loss: 0.3591 - val_accuracy: 0.9429\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0130 - accuracy: 0.9973 - val_loss: 0.3604 - val_accuracy: 0.9428\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0117 - accuracy: 0.9978 - val_loss: 0.3612 - val_accuracy: 0.9445\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.3600 - val_accuracy: 0.9440\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.3598 - val_accuracy: 0.9452\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 71us/sample - loss: 0.0089 - accuracy: 0.9986 - val_loss: 0.3638 - val_accuracy: 0.9442\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.3678 - val_accuracy: 0.9450\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.3681 - val_accuracy: 0.9454\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0068 - accuracy: 0.9991 - val_loss: 0.3699 - val_accuracy: 0.9458\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0064 - accuracy: 0.9993 - val_loss: 0.3706 - val_accuracy: 0.9457\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.3744 - val_accuracy: 0.9454\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0057 - accuracy: 0.9993 - val_loss: 0.3751 - val_accuracy: 0.9457\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0053 - accuracy: 0.9994 - val_loss: 0.3745 - val_accuracy: 0.9455\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.3777 - val_accuracy: 0.9466\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.3777 - val_accuracy: 0.9461\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.3808 - val_accuracy: 0.9466\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.3836 - val_accuracy: 0.9461\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0038 - accuracy: 0.9997 - val_loss: 0.3836 - val_accuracy: 0.9471\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0036 - accuracy: 0.9997 - val_loss: 0.3857 - val_accuracy: 0.9463\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.3888 - val_accuracy: 0.9457\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.3890 - val_accuracy: 0.9463\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.3917 - val_accuracy: 0.9466\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0030 - accuracy: 0.9998 - val_loss: 0.3915 - val_accuracy: 0.9457\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0028 - accuracy: 0.9998 - val_loss: 0.3914 - val_accuracy: 0.9470\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0027 - accuracy: 0.9998 - val_loss: 0.3939 - val_accuracy: 0.9460\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.3953 - val_accuracy: 0.9469\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.3973 - val_accuracy: 0.9463\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.3984 - val_accuracy: 0.9465\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.3980 - val_accuracy: 0.9472\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.3994 - val_accuracy: 0.9471\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.3987 - val_accuracy: 0.9474\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.4017 - val_accuracy: 0.9467\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.4025 - val_accuracy: 0.9465\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.4035 - val_accuracy: 0.9463\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 2s 71us/sample - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.4040 - val_accuracy: 0.9475\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.4063 - val_accuracy: 0.9468\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.4055 - val_accuracy: 0.9473\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.4062 - val_accuracy: 0.9473\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.4087 - val_accuracy: 0.9473\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.4085 - val_accuracy: 0.9470\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.4099 - val_accuracy: 0.9468\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 71us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.4105 - val_accuracy: 0.9466\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.4114 - val_accuracy: 0.9472\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.4122 - val_accuracy: 0.9472\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.4142 - val_accuracy: 0.9463\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.4141 - val_accuracy: 0.9468\n",
      "16000/16000 [==============================] - 0s 22us/sample - loss: 0.3956 - accuracy: 0.9462\n",
      "[CV]  learning_rate=0.0012211037261966795, n_hidden=2, n_neurons=161, n_softmax=20, total= 2.4min\n",
      "[CV] learning_rate=0.0012211037261966795, n_hidden=2, n_neurons=161, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 79us/sample - loss: 2.0722 - accuracy: 0.8063 - val_loss: 0.5853 - val_accuracy: 0.8733\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.4107 - accuracy: 0.8982 - val_loss: 0.4594 - val_accuracy: 0.8909\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 71us/sample - loss: 0.2897 - accuracy: 0.9214 - val_loss: 0.3907 - val_accuracy: 0.9107\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.2234 - accuracy: 0.9355 - val_loss: 0.3768 - val_accuracy: 0.9128\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.1842 - accuracy: 0.9457 - val_loss: 0.3507 - val_accuracy: 0.9179\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.1549 - accuracy: 0.9529 - val_loss: 0.3311 - val_accuracy: 0.9255\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.1329 - accuracy: 0.9594 - val_loss: 0.3344 - val_accuracy: 0.9286\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.1179 - accuracy: 0.9635 - val_loss: 0.3274 - val_accuracy: 0.9298\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.1035 - accuracy: 0.9678 - val_loss: 0.3079 - val_accuracy: 0.9348\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 71us/sample - loss: 0.0922 - accuracy: 0.9706 - val_loss: 0.3247 - val_accuracy: 0.9336\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0827 - accuracy: 0.9745 - val_loss: 0.3202 - val_accuracy: 0.9352\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0756 - accuracy: 0.9766 - val_loss: 0.3181 - val_accuracy: 0.9328\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0684 - accuracy: 0.9785 - val_loss: 0.3116 - val_accuracy: 0.9377\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0621 - accuracy: 0.9812 - val_loss: 0.3160 - val_accuracy: 0.9372\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.3179 - val_accuracy: 0.9370\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.3240 - val_accuracy: 0.9368\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0485 - accuracy: 0.9852 - val_loss: 0.3155 - val_accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0437 - accuracy: 0.9873 - val_loss: 0.3224 - val_accuracy: 0.9399\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0405 - accuracy: 0.9882 - val_loss: 0.3235 - val_accuracy: 0.9396\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0382 - accuracy: 0.9892 - val_loss: 0.3247 - val_accuracy: 0.9414\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.3291 - val_accuracy: 0.9397\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0329 - accuracy: 0.9915 - val_loss: 0.3250 - val_accuracy: 0.9423\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0304 - accuracy: 0.9916 - val_loss: 0.3318 - val_accuracy: 0.9412\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0282 - accuracy: 0.9931 - val_loss: 0.3281 - val_accuracy: 0.9406\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0268 - accuracy: 0.9932 - val_loss: 0.3346 - val_accuracy: 0.9412\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0254 - accuracy: 0.9936 - val_loss: 0.3362 - val_accuracy: 0.9423\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0232 - accuracy: 0.9947 - val_loss: 0.3402 - val_accuracy: 0.9422\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0224 - accuracy: 0.9943 - val_loss: 0.3353 - val_accuracy: 0.9433\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0207 - accuracy: 0.9952 - val_loss: 0.3379 - val_accuracy: 0.9417\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0200 - accuracy: 0.9952 - val_loss: 0.3385 - val_accuracy: 0.9421\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0184 - accuracy: 0.9958 - val_loss: 0.3474 - val_accuracy: 0.9423\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 72us/sample - loss: 0.0178 - accuracy: 0.9958 - val_loss: 0.3443 - val_accuracy: 0.9439\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0168 - accuracy: 0.9964 - val_loss: 0.3505 - val_accuracy: 0.9431\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0158 - accuracy: 0.9965 - val_loss: 0.3466 - val_accuracy: 0.9423\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.3493 - val_accuracy: 0.9447\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0147 - accuracy: 0.9970 - val_loss: 0.3528 - val_accuracy: 0.9441\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.3536 - val_accuracy: 0.9442\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0129 - accuracy: 0.9971 - val_loss: 0.3534 - val_accuracy: 0.9447\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.3543 - val_accuracy: 0.9452\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.3687 - val_accuracy: 0.9436\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.3623 - val_accuracy: 0.9438\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 744s 23ms/sample - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.3665 - val_accuracy: 0.9451\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.3647 - val_accuracy: 0.9454\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 3s 92us/sample - loss: 0.0098 - accuracy: 0.9981 - val_loss: 0.3658 - val_accuracy: 0.9448\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.3701 - val_accuracy: 0.9451\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0088 - accuracy: 0.9984 - val_loss: 0.3737 - val_accuracy: 0.9441\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.3726 - val_accuracy: 0.9447\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.3776 - val_accuracy: 0.9437\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.3769 - val_accuracy: 0.9437\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 71us/sample - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.3809 - val_accuracy: 0.9447\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 2s 70us/sample - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.3771 - val_accuracy: 0.9448\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.3809 - val_accuracy: 0.9452\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.3833 - val_accuracy: 0.9458\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0065 - accuracy: 0.9989 - val_loss: 0.3830 - val_accuracy: 0.9453\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.3869 - val_accuracy: 0.9448\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0061 - accuracy: 0.9989 - val_loss: 0.3890 - val_accuracy: 0.9454\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.3894 - val_accuracy: 0.9449\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0057 - accuracy: 0.9992 - val_loss: 0.3915 - val_accuracy: 0.9455\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0056 - accuracy: 0.9991 - val_loss: 0.3950 - val_accuracy: 0.9449\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.3946 - val_accuracy: 0.9450\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0051 - accuracy: 0.9993 - val_loss: 0.3956 - val_accuracy: 0.9455\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.3973 - val_accuracy: 0.9443\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.4004 - val_accuracy: 0.9450\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.3993 - val_accuracy: 0.9453\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.4008 - val_accuracy: 0.9454\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.4031 - val_accuracy: 0.9458\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.4060 - val_accuracy: 0.9456\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.4078 - val_accuracy: 0.9452\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.4094 - val_accuracy: 0.9456\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0041 - accuracy: 0.9995 - val_loss: 0.4107 - val_accuracy: 0.9458\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4099 - val_accuracy: 0.9453\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.4110 - val_accuracy: 0.9457\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0036 - accuracy: 0.9995 - val_loss: 0.4134 - val_accuracy: 0.9453\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.4134 - val_accuracy: 0.9451\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.4172 - val_accuracy: 0.9440\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.4161 - val_accuracy: 0.9454\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.4192 - val_accuracy: 0.9453\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.4186 - val_accuracy: 0.9453\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.4216 - val_accuracy: 0.9448\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.4243 - val_accuracy: 0.9453\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4227 - val_accuracy: 0.9454\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.4228 - val_accuracy: 0.9454\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.4232 - val_accuracy: 0.9451\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.4263 - val_accuracy: 0.9453\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.4327 - val_accuracy: 0.9450\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.4285 - val_accuracy: 0.9460\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.4284 - val_accuracy: 0.9461\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.4301 - val_accuracy: 0.9460\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.4316 - val_accuracy: 0.9461\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 2s 68us/sample - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.4333 - val_accuracy: 0.9457\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0027 - accuracy: 0.9996 - val_loss: 0.4341 - val_accuracy: 0.9454\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.4333 - val_accuracy: 0.9452\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0025 - accuracy: 0.9996 - val_loss: 0.4356 - val_accuracy: 0.9454\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 2s 66us/sample - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.4395 - val_accuracy: 0.9462\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.4392 - val_accuracy: 0.9448\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.4373 - val_accuracy: 0.9460\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4379 - val_accuracy: 0.9461\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 2s 69us/sample - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4395 - val_accuracy: 0.9457\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.4405 - val_accuracy: 0.9454\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 2s 67us/sample - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.4407 - val_accuracy: 0.9461\n",
      "16000/16000 [==============================] - 0s 23us/sample - loss: 0.4484 - accuracy: 0.9436\n",
      "[CV]  learning_rate=0.0012211037261966795, n_hidden=2, n_neurons=161, n_softmax=20, total=16.1min\n",
      "[CV] learning_rate=0.0019580903332522227, n_hidden=2, n_neurons=236, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 2.2127 - accuracy: 0.8146 - val_loss: 0.5385 - val_accuracy: 0.8735\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.3786 - accuracy: 0.9026 - val_loss: 0.4218 - val_accuracy: 0.8979\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.2600 - accuracy: 0.9294 - val_loss: 0.3681 - val_accuracy: 0.9218\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.2076 - accuracy: 0.9411 - val_loss: 0.3381 - val_accuracy: 0.9218\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.1632 - accuracy: 0.9514 - val_loss: 0.3452 - val_accuracy: 0.9278\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.1321 - accuracy: 0.9603 - val_loss: 0.3487 - val_accuracy: 0.9265\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.1139 - accuracy: 0.9654 - val_loss: 0.3181 - val_accuracy: 0.9334\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0947 - accuracy: 0.9710 - val_loss: 0.3360 - val_accuracy: 0.9320\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0822 - accuracy: 0.9747 - val_loss: 0.3281 - val_accuracy: 0.9372\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0718 - accuracy: 0.9779 - val_loss: 0.3390 - val_accuracy: 0.9348\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0613 - accuracy: 0.9808 - val_loss: 0.3256 - val_accuracy: 0.9377\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0531 - accuracy: 0.9838 - val_loss: 0.3395 - val_accuracy: 0.9373\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.3280 - val_accuracy: 0.9396\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0410 - accuracy: 0.9877 - val_loss: 0.3289 - val_accuracy: 0.9381\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0375 - accuracy: 0.9891 - val_loss: 0.3295 - val_accuracy: 0.9400\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0324 - accuracy: 0.9903 - val_loss: 0.3421 - val_accuracy: 0.9421\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0291 - accuracy: 0.9912 - val_loss: 0.3454 - val_accuracy: 0.9410\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0286 - accuracy: 0.9915 - val_loss: 0.3344 - val_accuracy: 0.9424\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0240 - accuracy: 0.9932 - val_loss: 0.3418 - val_accuracy: 0.9415\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0208 - accuracy: 0.9942 - val_loss: 0.3436 - val_accuracy: 0.9435\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0188 - accuracy: 0.9948 - val_loss: 0.3484 - val_accuracy: 0.9429\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.3520 - val_accuracy: 0.9423\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0152 - accuracy: 0.9961 - val_loss: 0.3559 - val_accuracy: 0.9437\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.3497 - val_accuracy: 0.9432\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.3498 - val_accuracy: 0.9445\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0122 - accuracy: 0.9967 - val_loss: 0.3611 - val_accuracy: 0.9451\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0110 - accuracy: 0.9973 - val_loss: 0.3622 - val_accuracy: 0.9443\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.3644 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.3634 - val_accuracy: 0.9460\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0088 - accuracy: 0.9977 - val_loss: 0.3677 - val_accuracy: 0.9442\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0085 - accuracy: 0.9978 - val_loss: 0.3668 - val_accuracy: 0.9444\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.3733 - val_accuracy: 0.9450\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0078 - accuracy: 0.9980 - val_loss: 0.3775 - val_accuracy: 0.9440\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0074 - accuracy: 0.9980 - val_loss: 0.3745 - val_accuracy: 0.9462\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.3761 - val_accuracy: 0.9460\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.3783 - val_accuracy: 0.9465\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.3810 - val_accuracy: 0.9464\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.3868 - val_accuracy: 0.9459\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.3814 - val_accuracy: 0.9461\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.3847 - val_accuracy: 0.9459\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.3858 - val_accuracy: 0.9463\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.3939 - val_accuracy: 0.9459\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.3917 - val_accuracy: 0.9464\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.3895 - val_accuracy: 0.9474\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.3929 - val_accuracy: 0.9464\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.3960 - val_accuracy: 0.9473\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.3994 - val_accuracy: 0.9461\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.3994 - val_accuracy: 0.9475\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.4006 - val_accuracy: 0.9469\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.4005 - val_accuracy: 0.9475\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.4034 - val_accuracy: 0.9468\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.4063 - val_accuracy: 0.9465\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4086 - val_accuracy: 0.9464\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.4059 - val_accuracy: 0.9466\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.4069 - val_accuracy: 0.9469\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.4092 - val_accuracy: 0.9473\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.4110 - val_accuracy: 0.9473\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.4118 - val_accuracy: 0.9473\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.4145 - val_accuracy: 0.9478\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.4140 - val_accuracy: 0.9470\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.4143 - val_accuracy: 0.9468\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.4146 - val_accuracy: 0.9473\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4162 - val_accuracy: 0.9475\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.4171 - val_accuracy: 0.9473\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4176 - val_accuracy: 0.9470\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4184 - val_accuracy: 0.9473\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4193 - val_accuracy: 0.9471\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4205 - val_accuracy: 0.9473\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4203 - val_accuracy: 0.9477\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4237 - val_accuracy: 0.9469\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4227 - val_accuracy: 0.9467\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.4262 - val_accuracy: 0.9478\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.4243 - val_accuracy: 0.9476\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.4258 - val_accuracy: 0.9475\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4267 - val_accuracy: 0.9473\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.4265 - val_accuracy: 0.9477\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.4277 - val_accuracy: 0.9468\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4292 - val_accuracy: 0.9478\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4297 - val_accuracy: 0.9474\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4299 - val_accuracy: 0.9477\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4303 - val_accuracy: 0.9476\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4304 - val_accuracy: 0.9475\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.4335 - val_accuracy: 0.9475\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4325 - val_accuracy: 0.9477\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.4333 - val_accuracy: 0.9478\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4337 - val_accuracy: 0.9470\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4355 - val_accuracy: 0.9478\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4362 - val_accuracy: 0.9479\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4356 - val_accuracy: 0.9480\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.4353 - val_accuracy: 0.9477\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.4383 - val_accuracy: 0.9478\n",
      "16000/16000 [==============================] - 0s 24us/sample - loss: 0.4274 - accuracy: 0.9503\n",
      "[CV]  learning_rate=0.0019580903332522227, n_hidden=2, n_neurons=236, n_softmax=10, total= 3.6min\n",
      "[CV] learning_rate=0.0019580903332522227, n_hidden=2, n_neurons=236, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 2.4152 - accuracy: 0.7885 - val_loss: 0.5567 - val_accuracy: 0.8675\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.4129 - accuracy: 0.8944 - val_loss: 0.4417 - val_accuracy: 0.8882\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.3088 - accuracy: 0.9170 - val_loss: 0.3876 - val_accuracy: 0.9100\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.2539 - accuracy: 0.9312 - val_loss: 0.3377 - val_accuracy: 0.9232\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.2146 - accuracy: 0.9389 - val_loss: 0.3373 - val_accuracy: 0.9211\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.1880 - accuracy: 0.9464 - val_loss: 0.3213 - val_accuracy: 0.9254\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.1636 - accuracy: 0.9523 - val_loss: 0.3133 - val_accuracy: 0.9312\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.1476 - accuracy: 0.9555 - val_loss: 0.3026 - val_accuracy: 0.9323\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.1343 - accuracy: 0.9596 - val_loss: 0.3027 - val_accuracy: 0.9328\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.1238 - accuracy: 0.9628 - val_loss: 0.3223 - val_accuracy: 0.9338\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.1141 - accuracy: 0.9664 - val_loss: 0.2902 - val_accuracy: 0.9390\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.1055 - accuracy: 0.9679 - val_loss: 0.3090 - val_accuracy: 0.9342\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0966 - accuracy: 0.9695 - val_loss: 0.2975 - val_accuracy: 0.9380\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0868 - accuracy: 0.9727 - val_loss: 0.2917 - val_accuracy: 0.9393\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0810 - accuracy: 0.9751 - val_loss: 0.3032 - val_accuracy: 0.9402\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0743 - accuracy: 0.9769 - val_loss: 0.2973 - val_accuracy: 0.9405\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0710 - accuracy: 0.9777 - val_loss: 0.2932 - val_accuracy: 0.9427\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0665 - accuracy: 0.9795 - val_loss: 0.3163 - val_accuracy: 0.9399\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0617 - accuracy: 0.9806 - val_loss: 0.3156 - val_accuracy: 0.9398\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0595 - accuracy: 0.9815 - val_loss: 0.3021 - val_accuracy: 0.9435\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0551 - accuracy: 0.9827 - val_loss: 0.3009 - val_accuracy: 0.9433\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0527 - accuracy: 0.9838 - val_loss: 0.3117 - val_accuracy: 0.9435\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0478 - accuracy: 0.9850 - val_loss: 0.3250 - val_accuracy: 0.9415\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0460 - accuracy: 0.9852 - val_loss: 0.3268 - val_accuracy: 0.9402\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0423 - accuracy: 0.9866 - val_loss: 0.3271 - val_accuracy: 0.9423\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0401 - accuracy: 0.9875 - val_loss: 0.3208 - val_accuracy: 0.9438\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.3354 - val_accuracy: 0.9442\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0366 - accuracy: 0.9888 - val_loss: 0.3234 - val_accuracy: 0.9445\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0328 - accuracy: 0.9899 - val_loss: 0.3370 - val_accuracy: 0.9452\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0335 - accuracy: 0.9897 - val_loss: 0.3455 - val_accuracy: 0.9447\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.3448 - val_accuracy: 0.9433\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0275 - accuracy: 0.9919 - val_loss: 0.3520 - val_accuracy: 0.9421\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.3574 - val_accuracy: 0.9438\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0253 - accuracy: 0.9928 - val_loss: 0.3797 - val_accuracy: 0.9392\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.3616 - val_accuracy: 0.9448\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.3692 - val_accuracy: 0.9429\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0232 - accuracy: 0.9932 - val_loss: 0.3691 - val_accuracy: 0.9446\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.3802 - val_accuracy: 0.9421\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0201 - accuracy: 0.9942 - val_loss: 0.3693 - val_accuracy: 0.9432\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0191 - accuracy: 0.9946 - val_loss: 0.3711 - val_accuracy: 0.9447\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0182 - accuracy: 0.9946 - val_loss: 0.3784 - val_accuracy: 0.9443\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0171 - accuracy: 0.9952 - val_loss: 0.3747 - val_accuracy: 0.9436\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0176 - accuracy: 0.9948 - val_loss: 0.3824 - val_accuracy: 0.9434\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.3834 - val_accuracy: 0.9440\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.3821 - val_accuracy: 0.9457\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0167 - accuracy: 0.9952 - val_loss: 0.3861 - val_accuracy: 0.9452\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0147 - accuracy: 0.9955 - val_loss: 0.3897 - val_accuracy: 0.9446\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.3923 - val_accuracy: 0.9438\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0128 - accuracy: 0.9962 - val_loss: 0.3956 - val_accuracy: 0.9430\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0129 - accuracy: 0.9962 - val_loss: 0.3964 - val_accuracy: 0.9448\n",
      "Epoch 51/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0127 - accuracy: 0.9963 - val_loss: 0.4089 - val_accuracy: 0.9442\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.4055 - val_accuracy: 0.9441\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.4098 - val_accuracy: 0.9452\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.4140 - val_accuracy: 0.9443\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.4107 - val_accuracy: 0.9435\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0103 - accuracy: 0.9969 - val_loss: 0.4148 - val_accuracy: 0.9445\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.4220 - val_accuracy: 0.9448\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.4221 - val_accuracy: 0.9442\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0096 - accuracy: 0.9970 - val_loss: 0.4209 - val_accuracy: 0.9439\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.4241 - val_accuracy: 0.9442\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.4384 - val_accuracy: 0.9426\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 0.4231 - val_accuracy: 0.9450\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0081 - accuracy: 0.9975 - val_loss: 0.4267 - val_accuracy: 0.9449\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.4288 - val_accuracy: 0.9452\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.4310 - val_accuracy: 0.9444\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.4360 - val_accuracy: 0.9446\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.4366 - val_accuracy: 0.9462\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0068 - accuracy: 0.9979 - val_loss: 0.4391 - val_accuracy: 0.9452\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.4400 - val_accuracy: 0.9447\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.4444 - val_accuracy: 0.9447\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.4506 - val_accuracy: 0.9450\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0063 - accuracy: 0.9981 - val_loss: 0.4469 - val_accuracy: 0.9448\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.4535 - val_accuracy: 0.9452\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.4514 - val_accuracy: 0.9442\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.4502 - val_accuracy: 0.9448\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.4513 - val_accuracy: 0.9462\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4551 - val_accuracy: 0.9457\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0056 - accuracy: 0.9982 - val_loss: 0.4501 - val_accuracy: 0.9461\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.4566 - val_accuracy: 0.9456\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.4581 - val_accuracy: 0.9459\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.4600 - val_accuracy: 0.9461\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.4627 - val_accuracy: 0.9457\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.4625 - val_accuracy: 0.9448\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.4694 - val_accuracy: 0.9456\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4642 - val_accuracy: 0.9463\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.4623 - val_accuracy: 0.9452\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.4689 - val_accuracy: 0.9453\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.4752 - val_accuracy: 0.9458\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.4711 - val_accuracy: 0.9452\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.4720 - val_accuracy: 0.9448\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.4749 - val_accuracy: 0.9458\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.4762 - val_accuracy: 0.9441\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.4769 - val_accuracy: 0.9452\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.4773 - val_accuracy: 0.9450\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.4800 - val_accuracy: 0.9454\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.4831 - val_accuracy: 0.9452\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0046 - accuracy: 0.9985 - val_loss: 0.4802 - val_accuracy: 0.9456\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.4821 - val_accuracy: 0.9460\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4851 - val_accuracy: 0.9460\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4830 - val_accuracy: 0.9461\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.4542 - accuracy: 0.9490\n",
      "[CV]  learning_rate=0.0019580903332522227, n_hidden=2, n_neurons=236, n_softmax=10, total= 4.0min\n",
      "[CV] learning_rate=0.0019580903332522227, n_hidden=2, n_neurons=236, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 2.3285 - accuracy: 0.7805 - val_loss: 0.5564 - val_accuracy: 0.8760\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.4006 - accuracy: 0.8958 - val_loss: 0.4153 - val_accuracy: 0.9006\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.2958 - accuracy: 0.9211 - val_loss: 0.3659 - val_accuracy: 0.9134\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.2349 - accuracy: 0.9346 - val_loss: 0.3688 - val_accuracy: 0.9115\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.2000 - accuracy: 0.9428 - val_loss: 0.3283 - val_accuracy: 0.9256\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.1711 - accuracy: 0.9511 - val_loss: 0.3197 - val_accuracy: 0.9263\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.1516 - accuracy: 0.9551 - val_loss: 0.3270 - val_accuracy: 0.9269\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.1341 - accuracy: 0.9596 - val_loss: 0.3108 - val_accuracy: 0.9312\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.1198 - accuracy: 0.9633 - val_loss: 0.3160 - val_accuracy: 0.9301\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.1092 - accuracy: 0.9664 - val_loss: 0.3197 - val_accuracy: 0.9317\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0969 - accuracy: 0.9695 - val_loss: 0.3097 - val_accuracy: 0.9351\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0903 - accuracy: 0.9716 - val_loss: 0.3087 - val_accuracy: 0.9338\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0834 - accuracy: 0.9739 - val_loss: 0.2984 - val_accuracy: 0.9374\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0768 - accuracy: 0.9762 - val_loss: 0.3062 - val_accuracy: 0.9377\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0697 - accuracy: 0.9779 - val_loss: 0.3145 - val_accuracy: 0.9372\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0642 - accuracy: 0.9789 - val_loss: 0.3125 - val_accuracy: 0.9389\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0614 - accuracy: 0.9812 - val_loss: 0.3108 - val_accuracy: 0.9407\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0554 - accuracy: 0.9824 - val_loss: 0.3250 - val_accuracy: 0.9398\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0514 - accuracy: 0.9841 - val_loss: 0.3130 - val_accuracy: 0.9420\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0486 - accuracy: 0.9845 - val_loss: 0.3311 - val_accuracy: 0.9405\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0468 - accuracy: 0.9852 - val_loss: 0.3150 - val_accuracy: 0.9420\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0435 - accuracy: 0.9863 - val_loss: 0.3223 - val_accuracy: 0.9411\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0409 - accuracy: 0.9872 - val_loss: 0.3346 - val_accuracy: 0.9408\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0374 - accuracy: 0.9881 - val_loss: 0.3229 - val_accuracy: 0.9414\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0341 - accuracy: 0.9897 - val_loss: 0.3225 - val_accuracy: 0.9446\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0326 - accuracy: 0.9899 - val_loss: 0.3270 - val_accuracy: 0.9430\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0313 - accuracy: 0.9905 - val_loss: 0.3268 - val_accuracy: 0.9433\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.3314 - val_accuracy: 0.9440\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0274 - accuracy: 0.9916 - val_loss: 0.3348 - val_accuracy: 0.9445\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.3351 - val_accuracy: 0.9442\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0258 - accuracy: 0.9924 - val_loss: 0.3323 - val_accuracy: 0.9450\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0230 - accuracy: 0.9935 - val_loss: 0.3396 - val_accuracy: 0.9442\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.3483 - val_accuracy: 0.9448\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.3457 - val_accuracy: 0.9446\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.3524 - val_accuracy: 0.9445\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 2s 73us/sample - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.3721 - val_accuracy: 0.9421\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 4s 114us/sample - loss: 0.0191 - accuracy: 0.9945 - val_loss: 0.3565 - val_accuracy: 0.9440\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0168 - accuracy: 0.9954 - val_loss: 0.3587 - val_accuracy: 0.9437\n",
      "Epoch 39/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.3666 - val_accuracy: 0.9456\n",
      "Epoch 40/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0154 - accuracy: 0.9957 - val_loss: 0.3639 - val_accuracy: 0.9457\n",
      "Epoch 41/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.3682 - val_accuracy: 0.9450\n",
      "Epoch 42/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.3720 - val_accuracy: 0.9455\n",
      "Epoch 43/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.3731 - val_accuracy: 0.9446\n",
      "Epoch 44/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0136 - accuracy: 0.9961 - val_loss: 0.3805 - val_accuracy: 0.9457\n",
      "Epoch 45/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0130 - accuracy: 0.9964 - val_loss: 0.3786 - val_accuracy: 0.9459\n",
      "Epoch 46/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0127 - accuracy: 0.9964 - val_loss: 0.3834 - val_accuracy: 0.9458\n",
      "Epoch 47/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0125 - accuracy: 0.9965 - val_loss: 0.3755 - val_accuracy: 0.9448\n",
      "Epoch 48/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0118 - accuracy: 0.9967 - val_loss: 0.3817 - val_accuracy: 0.9442\n",
      "Epoch 49/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.3790 - val_accuracy: 0.9442\n",
      "Epoch 50/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.3845 - val_accuracy: 0.9462\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0107 - accuracy: 0.9973 - val_loss: 0.3857 - val_accuracy: 0.9452\n",
      "Epoch 52/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.3943 - val_accuracy: 0.9452\n",
      "Epoch 53/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.3894 - val_accuracy: 0.9461\n",
      "Epoch 54/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.3986 - val_accuracy: 0.9458\n",
      "Epoch 55/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.3985 - val_accuracy: 0.9459\n",
      "Epoch 56/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.3957 - val_accuracy: 0.9445\n",
      "Epoch 57/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.3994 - val_accuracy: 0.9441\n",
      "Epoch 58/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0079 - accuracy: 0.9979 - val_loss: 0.4036 - val_accuracy: 0.9451\n",
      "Epoch 59/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.4066 - val_accuracy: 0.9448\n",
      "Epoch 60/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.4066 - val_accuracy: 0.9442\n",
      "Epoch 61/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.4094 - val_accuracy: 0.9452\n",
      "Epoch 62/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0071 - accuracy: 0.9982 - val_loss: 0.4082 - val_accuracy: 0.9466\n",
      "Epoch 63/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.4131 - val_accuracy: 0.9447\n",
      "Epoch 64/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.4175 - val_accuracy: 0.9451\n",
      "Epoch 65/100\n",
      "32000/32000 [==============================] - 2s 78us/sample - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.4161 - val_accuracy: 0.9457\n",
      "Epoch 66/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.4183 - val_accuracy: 0.9453\n",
      "Epoch 67/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.4206 - val_accuracy: 0.9455\n",
      "Epoch 68/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.4155 - val_accuracy: 0.9453\n",
      "Epoch 69/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.4240 - val_accuracy: 0.9442\n",
      "Epoch 70/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.4266 - val_accuracy: 0.9446\n",
      "Epoch 71/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.4321 - val_accuracy: 0.9448\n",
      "Epoch 72/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.4199 - val_accuracy: 0.9458\n",
      "Epoch 73/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.4264 - val_accuracy: 0.9459\n",
      "Epoch 74/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.4319 - val_accuracy: 0.9459\n",
      "Epoch 75/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.4288 - val_accuracy: 0.9450\n",
      "Epoch 76/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.4334 - val_accuracy: 0.9463\n",
      "Epoch 77/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.4360 - val_accuracy: 0.9462\n",
      "Epoch 78/100\n",
      "32000/32000 [==============================] - 3s 78us/sample - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.4371 - val_accuracy: 0.9454\n",
      "Epoch 79/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.4429 - val_accuracy: 0.9442\n",
      "Epoch 80/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.4398 - val_accuracy: 0.9448\n",
      "Epoch 81/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.4394 - val_accuracy: 0.9451\n",
      "Epoch 82/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.4429 - val_accuracy: 0.9449\n",
      "Epoch 83/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.4422 - val_accuracy: 0.9449\n",
      "Epoch 84/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.4456 - val_accuracy: 0.9461\n",
      "Epoch 85/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.4598 - val_accuracy: 0.9445\n",
      "Epoch 86/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.4468 - val_accuracy: 0.9455\n",
      "Epoch 87/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.4446 - val_accuracy: 0.9457\n",
      "Epoch 88/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.4486 - val_accuracy: 0.9460\n",
      "Epoch 89/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.4567 - val_accuracy: 0.9458\n",
      "Epoch 90/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.4534 - val_accuracy: 0.9448\n",
      "Epoch 91/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.4554 - val_accuracy: 0.9457\n",
      "Epoch 92/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.4527 - val_accuracy: 0.9449\n",
      "Epoch 93/100\n",
      "32000/32000 [==============================] - 2s 74us/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4575 - val_accuracy: 0.9457\n",
      "Epoch 94/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.4729 - val_accuracy: 0.9443\n",
      "Epoch 95/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.4582 - val_accuracy: 0.9446\n",
      "Epoch 96/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.4568 - val_accuracy: 0.9457\n",
      "Epoch 97/100\n",
      "32000/32000 [==============================] - 2s 76us/sample - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.4599 - val_accuracy: 0.9451\n",
      "Epoch 98/100\n",
      "32000/32000 [==============================] - 2s 77us/sample - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.4619 - val_accuracy: 0.9450\n",
      "Epoch 99/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.4584 - val_accuracy: 0.9452\n",
      "Epoch 100/100\n",
      "32000/32000 [==============================] - 2s 75us/sample - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.4667 - val_accuracy: 0.9452\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.4569 - accuracy: 0.9482\n",
      "[CV]  learning_rate=0.0019580903332522227, n_hidden=2, n_neurons=236, n_softmax=10, total= 4.1min\n",
      "[CV] learning_rate=0.0013770560347033606, n_hidden=4, n_neurons=170, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 96us/sample - loss: 1.1341 - accuracy: 0.8287 - val_loss: 0.3976 - val_accuracy: 0.9001\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.2706 - accuracy: 0.9240 - val_loss: 0.3219 - val_accuracy: 0.9175\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.1765 - accuracy: 0.9479 - val_loss: 0.2893 - val_accuracy: 0.9269\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 85us/sample - loss: 0.1267 - accuracy: 0.9622 - val_loss: 0.2640 - val_accuracy: 0.9338\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0935 - accuracy: 0.9719 - val_loss: 0.2464 - val_accuracy: 0.9378\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0710 - accuracy: 0.9784 - val_loss: 0.2632 - val_accuracy: 0.9360\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0530 - accuracy: 0.9845 - val_loss: 0.2425 - val_accuracy: 0.9426\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0418 - accuracy: 0.9884 - val_loss: 0.2547 - val_accuracy: 0.9413\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0311 - accuracy: 0.9917 - val_loss: 0.2472 - val_accuracy: 0.9455\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0241 - accuracy: 0.9948 - val_loss: 0.2507 - val_accuracy: 0.9448\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0185 - accuracy: 0.9967 - val_loss: 0.2527 - val_accuracy: 0.9457\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.2538 - val_accuracy: 0.9467\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.2552 - val_accuracy: 0.9473\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.2574 - val_accuracy: 0.9483\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0073 - accuracy: 0.9993 - val_loss: 0.2612 - val_accuracy: 0.9475\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0061 - accuracy: 0.9997 - val_loss: 0.2618 - val_accuracy: 0.9479\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.2646 - val_accuracy: 0.9488\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0044 - accuracy: 0.9999 - val_loss: 0.2667 - val_accuracy: 0.9487\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.2693 - val_accuracy: 0.9488\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0035 - accuracy: 0.9999 - val_loss: 0.2731 - val_accuracy: 0.9486\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2730 - val_accuracy: 0.9493\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2751 - val_accuracy: 0.9496\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2759 - val_accuracy: 0.9497\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2768 - val_accuracy: 0.9496\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2784 - val_accuracy: 0.9492\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 85us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2798 - val_accuracy: 0.9497\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 86us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 0.9497\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2818 - val_accuracy: 0.9495\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9498\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2836 - val_accuracy: 0.9500\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2854 - val_accuracy: 0.9496\n",
      "16000/16000 [==============================] - 0s 26us/sample - loss: 0.2879 - accuracy: 0.9479\n",
      "[CV]  learning_rate=0.0013770560347033606, n_hidden=4, n_neurons=170, n_softmax=20, total= 1.4min\n",
      "[CV] learning_rate=0.0013770560347033606, n_hidden=4, n_neurons=170, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 94us/sample - loss: 1.0448 - accuracy: 0.8238 - val_loss: 0.4133 - val_accuracy: 0.8859\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.2776 - accuracy: 0.9199 - val_loss: 0.3050 - val_accuracy: 0.9131\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.1854 - accuracy: 0.9451 - val_loss: 0.2813 - val_accuracy: 0.9249\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.1321 - accuracy: 0.9603 - val_loss: 0.2497 - val_accuracy: 0.9327\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0998 - accuracy: 0.9703 - val_loss: 0.2385 - val_accuracy: 0.9351\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0784 - accuracy: 0.9767 - val_loss: 0.2269 - val_accuracy: 0.9413\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0607 - accuracy: 0.9818 - val_loss: 0.2370 - val_accuracy: 0.9413\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0480 - accuracy: 0.9870 - val_loss: 0.2264 - val_accuracy: 0.9440\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0375 - accuracy: 0.9898 - val_loss: 0.2332 - val_accuracy: 0.9449\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0295 - accuracy: 0.9929 - val_loss: 0.2245 - val_accuracy: 0.9461\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0240 - accuracy: 0.9948 - val_loss: 0.2246 - val_accuracy: 0.9459\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0192 - accuracy: 0.9964 - val_loss: 0.2287 - val_accuracy: 0.9434\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0153 - accuracy: 0.9974 - val_loss: 0.2240 - val_accuracy: 0.9473\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0128 - accuracy: 0.9981 - val_loss: 0.2269 - val_accuracy: 0.9483\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0103 - accuracy: 0.9988 - val_loss: 0.2290 - val_accuracy: 0.9497\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.2289 - val_accuracy: 0.9492\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0073 - accuracy: 0.9994 - val_loss: 0.2295 - val_accuracy: 0.9495\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0065 - accuracy: 0.9995 - val_loss: 0.2335 - val_accuracy: 0.9505\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0054 - accuracy: 0.9997 - val_loss: 0.2352 - val_accuracy: 0.9509\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0048 - accuracy: 0.9997 - val_loss: 0.2354 - val_accuracy: 0.9505\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 85us/sample - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.2368 - val_accuracy: 0.9501\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.2387 - val_accuracy: 0.9508\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.2411 - val_accuracy: 0.9508\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0031 - accuracy: 0.9999 - val_loss: 0.2422 - val_accuracy: 0.9513\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2424 - val_accuracy: 0.9517\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2440 - val_accuracy: 0.9507\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2451 - val_accuracy: 0.9519\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9521\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9522\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9520\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2489 - val_accuracy: 0.9523\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 3s 85us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2496 - val_accuracy: 0.9520\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 0.9523\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9525\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2525 - val_accuracy: 0.9530\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9528\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2534 - val_accuracy: 0.9529\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2544 - val_accuracy: 0.9533\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.2606 - accuracy: 0.9521\n",
      "[CV]  learning_rate=0.0013770560347033606, n_hidden=4, n_neurons=170, n_softmax=20, total= 1.7min\n",
      "[CV] learning_rate=0.0013770560347033606, n_hidden=4, n_neurons=170, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 95us/sample - loss: 1.0811 - accuracy: 0.8167 - val_loss: 0.4066 - val_accuracy: 0.8914\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.2906 - accuracy: 0.9143 - val_loss: 0.3170 - val_accuracy: 0.9121\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.2003 - accuracy: 0.9394 - val_loss: 0.2893 - val_accuracy: 0.9224\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.1480 - accuracy: 0.9530 - val_loss: 0.2660 - val_accuracy: 0.9291\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.1158 - accuracy: 0.9643 - val_loss: 0.2557 - val_accuracy: 0.9344\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0922 - accuracy: 0.9709 - val_loss: 0.2537 - val_accuracy: 0.9362\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0742 - accuracy: 0.9779 - val_loss: 0.2401 - val_accuracy: 0.9408\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0596 - accuracy: 0.9822 - val_loss: 0.2447 - val_accuracy: 0.9400\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0468 - accuracy: 0.9868 - val_loss: 0.2408 - val_accuracy: 0.9423\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0388 - accuracy: 0.9896 - val_loss: 0.2403 - val_accuracy: 0.9427\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 85us/sample - loss: 0.0318 - accuracy: 0.9923 - val_loss: 0.2446 - val_accuracy: 0.9430\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0262 - accuracy: 0.9940 - val_loss: 0.2485 - val_accuracy: 0.9430\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0215 - accuracy: 0.9953 - val_loss: 0.2533 - val_accuracy: 0.9446\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0179 - accuracy: 0.9962 - val_loss: 0.2533 - val_accuracy: 0.9462\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0142 - accuracy: 0.9976 - val_loss: 0.2510 - val_accuracy: 0.9452\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0119 - accuracy: 0.9983 - val_loss: 0.2554 - val_accuracy: 0.9466\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0101 - accuracy: 0.9986 - val_loss: 0.2534 - val_accuracy: 0.9473\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0085 - accuracy: 0.9992 - val_loss: 0.2560 - val_accuracy: 0.9471\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0070 - accuracy: 0.9996 - val_loss: 0.2590 - val_accuracy: 0.9477\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.2606 - val_accuracy: 0.9481\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.2671 - val_accuracy: 0.9472\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0049 - accuracy: 0.9999 - val_loss: 0.2629 - val_accuracy: 0.9488\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0044 - accuracy: 0.9998 - val_loss: 0.2660 - val_accuracy: 0.9483\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 85us/sample - loss: 0.0039 - accuracy: 0.9999 - val_loss: 0.2688 - val_accuracy: 0.9488\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2707 - val_accuracy: 0.9488\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.2726 - val_accuracy: 0.9490\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.2734 - val_accuracy: 0.9489\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2736 - val_accuracy: 0.9493\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2752 - val_accuracy: 0.9491\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 0.9496\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2796 - val_accuracy: 0.9494\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2800 - val_accuracy: 0.9497\n",
      "Epoch 33/100\n",
      "32000/32000 [==============================] - 3s 82us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2810 - val_accuracy: 0.9493\n",
      "Epoch 34/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2814 - val_accuracy: 0.9495\n",
      "Epoch 35/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2829 - val_accuracy: 0.9503\n",
      "Epoch 36/100\n",
      "32000/32000 [==============================] - 3s 84us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 0.9501\n",
      "Epoch 37/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2855 - val_accuracy: 0.9499\n",
      "Epoch 38/100\n",
      "32000/32000 [==============================] - 3s 83us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2861 - val_accuracy: 0.9502\n",
      "16000/16000 [==============================] - 0s 25us/sample - loss: 0.2623 - accuracy: 0.9528\n",
      "[CV]  learning_rate=0.0013770560347033606, n_hidden=4, n_neurons=170, n_softmax=20, total= 1.7min\n",
      "[CV] learning_rate=0.0013784417588715953, n_hidden=4, n_neurons=190, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 104us/sample - loss: 1.0270 - accuracy: 0.8235 - val_loss: 0.3852 - val_accuracy: 0.8989\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.2628 - accuracy: 0.9229 - val_loss: 0.3089 - val_accuracy: 0.9133\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.1670 - accuracy: 0.9484 - val_loss: 0.2765 - val_accuracy: 0.9248\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.1169 - accuracy: 0.9648 - val_loss: 0.2541 - val_accuracy: 0.9330\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0831 - accuracy: 0.9740 - val_loss: 0.2615 - val_accuracy: 0.9339\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0624 - accuracy: 0.9814 - val_loss: 0.2403 - val_accuracy: 0.9401\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0454 - accuracy: 0.9874 - val_loss: 0.2378 - val_accuracy: 0.9424\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0334 - accuracy: 0.9917 - val_loss: 0.2445 - val_accuracy: 0.9427\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0249 - accuracy: 0.9948 - val_loss: 0.2414 - val_accuracy: 0.9447\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0189 - accuracy: 0.9966 - val_loss: 0.2430 - val_accuracy: 0.9453\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0142 - accuracy: 0.9981 - val_loss: 0.2463 - val_accuracy: 0.9460\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 4s 110us/sample - loss: 0.0107 - accuracy: 0.9990 - val_loss: 0.2472 - val_accuracy: 0.9467\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0083 - accuracy: 0.9995 - val_loss: 0.2517 - val_accuracy: 0.9488\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0067 - accuracy: 0.9998 - val_loss: 0.2511 - val_accuracy: 0.9488\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0056 - accuracy: 0.9998 - val_loss: 0.2541 - val_accuracy: 0.9497\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.2546 - val_accuracy: 0.9496\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.2569 - val_accuracy: 0.9497\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.2585 - val_accuracy: 0.9498\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.2615 - val_accuracy: 0.9498\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2629 - val_accuracy: 0.9499\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2640 - val_accuracy: 0.9505\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2649 - val_accuracy: 0.9503\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 91us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2664 - val_accuracy: 0.9504\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2675 - val_accuracy: 0.9506\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9504\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2699 - val_accuracy: 0.9509\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 0.9504\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 0.9507\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2721 - val_accuracy: 0.9508\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2732 - val_accuracy: 0.9507\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2748 - val_accuracy: 0.9511\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2749 - val_accuracy: 0.9507\n",
      "16000/16000 [==============================] - 0s 28us/sample - loss: 0.2717 - accuracy: 0.9480\n",
      "[CV]  learning_rate=0.0013784417588715953, n_hidden=4, n_neurons=190, n_softmax=20, total= 1.6min\n",
      "[CV] learning_rate=0.0013784417588715953, n_hidden=4, n_neurons=190, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 99us/sample - loss: 0.9634 - accuracy: 0.8367 - val_loss: 0.4447 - val_accuracy: 0.8820\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.2505 - accuracy: 0.9273 - val_loss: 0.3135 - val_accuracy: 0.9186\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.1607 - accuracy: 0.9511 - val_loss: 0.2665 - val_accuracy: 0.9287\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.1067 - accuracy: 0.9668 - val_loss: 0.2540 - val_accuracy: 0.9345\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0778 - accuracy: 0.9756 - val_loss: 0.2506 - val_accuracy: 0.9374\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0551 - accuracy: 0.9837 - val_loss: 0.2627 - val_accuracy: 0.9361\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0397 - accuracy: 0.9893 - val_loss: 0.2436 - val_accuracy: 0.9419\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0301 - accuracy: 0.9925 - val_loss: 0.2459 - val_accuracy: 0.9432\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0220 - accuracy: 0.9953 - val_loss: 0.2407 - val_accuracy: 0.9452\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0167 - accuracy: 0.9972 - val_loss: 0.2433 - val_accuracy: 0.9451\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0128 - accuracy: 0.9982 - val_loss: 0.2425 - val_accuracy: 0.9459\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0100 - accuracy: 0.9989 - val_loss: 0.2485 - val_accuracy: 0.9462\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.2485 - val_accuracy: 0.9469\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0065 - accuracy: 0.9996 - val_loss: 0.2510 - val_accuracy: 0.9467\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.2523 - val_accuracy: 0.9473\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 90us/sample - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.2534 - val_accuracy: 0.9478\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.2537 - val_accuracy: 0.9480\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.2561 - val_accuracy: 0.9476\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0032 - accuracy: 0.9999 - val_loss: 0.2556 - val_accuracy: 0.9488\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.2579 - val_accuracy: 0.9482\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.2590 - val_accuracy: 0.9493\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9485\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2614 - val_accuracy: 0.9495\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2627 - val_accuracy: 0.9498\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2631 - val_accuracy: 0.9499\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2643 - val_accuracy: 0.9498\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.9503\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 0.9491\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9491\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2680 - val_accuracy: 0.9494\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2686 - val_accuracy: 0.9501\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2688 - val_accuracy: 0.9498\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.2642 - accuracy: 0.9527\n",
      "[CV]  learning_rate=0.0013784417588715953, n_hidden=4, n_neurons=190, n_softmax=20, total= 1.5min\n",
      "[CV] learning_rate=0.0013784417588715953, n_hidden=4, n_neurons=190, n_softmax=20 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 3s 100us/sample - loss: 0.9915 - accuracy: 0.8236 - val_loss: 0.3808 - val_accuracy: 0.8980\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.2670 - accuracy: 0.9223 - val_loss: 0.3141 - val_accuracy: 0.9138\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.1762 - accuracy: 0.9467 - val_loss: 0.2657 - val_accuracy: 0.9291\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.1209 - accuracy: 0.9622 - val_loss: 0.2481 - val_accuracy: 0.9345\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0909 - accuracy: 0.9720 - val_loss: 0.2391 - val_accuracy: 0.9371\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0663 - accuracy: 0.9792 - val_loss: 0.2489 - val_accuracy: 0.9358\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0486 - accuracy: 0.9859 - val_loss: 0.2381 - val_accuracy: 0.9417\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0374 - accuracy: 0.9901 - val_loss: 0.2329 - val_accuracy: 0.9439\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0272 - accuracy: 0.9938 - val_loss: 0.2335 - val_accuracy: 0.9451\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0205 - accuracy: 0.9962 - val_loss: 0.2383 - val_accuracy: 0.9448\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0157 - accuracy: 0.9979 - val_loss: 0.2416 - val_accuracy: 0.9450\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0117 - accuracy: 0.9988 - val_loss: 0.2429 - val_accuracy: 0.9457\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.2421 - val_accuracy: 0.9482\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.2462 - val_accuracy: 0.9480\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0063 - accuracy: 0.9997 - val_loss: 0.2482 - val_accuracy: 0.9491\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 3s 86us/sample - loss: 0.0053 - accuracy: 0.9999 - val_loss: 0.2501 - val_accuracy: 0.9480\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.2519 - val_accuracy: 0.9491\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0040 - accuracy: 0.9999 - val_loss: 0.2537 - val_accuracy: 0.9491\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.2545 - val_accuracy: 0.9491\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 0.9492\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0029 - accuracy: 0.9999 - val_loss: 0.2573 - val_accuracy: 0.9502\n",
      "Epoch 22/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.2589 - val_accuracy: 0.9497\n",
      "Epoch 23/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2608 - val_accuracy: 0.9501\n",
      "Epoch 24/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2624 - val_accuracy: 0.9496\n",
      "Epoch 25/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.2623 - val_accuracy: 0.9507\n",
      "Epoch 26/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.2639 - val_accuracy: 0.9503\n",
      "Epoch 27/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.2638 - val_accuracy: 0.9504\n",
      "Epoch 28/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9512\n",
      "Epoch 29/100\n",
      "32000/32000 [==============================] - 3s 89us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2668 - val_accuracy: 0.9507\n",
      "Epoch 30/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2685 - val_accuracy: 0.9508\n",
      "Epoch 31/100\n",
      "32000/32000 [==============================] - 3s 87us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2692 - val_accuracy: 0.9512\n",
      "Epoch 32/100\n",
      "32000/32000 [==============================] - 3s 88us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2695 - val_accuracy: 0.9511\n",
      "16000/16000 [==============================] - 0s 27us/sample - loss: 0.2705 - accuracy: 0.9509\n",
      "[CV]  learning_rate=0.0013784417588715953, n_hidden=4, n_neurons=190, n_softmax=20, total= 1.5min\n",
      "[CV] learning_rate=0.0023693222883062726, n_hidden=4, n_neurons=364, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 4s 131us/sample - loss: 1.0355 - accuracy: 0.8560 - val_loss: 0.2911 - val_accuracy: 0.9163\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 4s 123us/sample - loss: 0.1700 - accuracy: 0.9500 - val_loss: 0.2408 - val_accuracy: 0.9337\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 0.0848 - accuracy: 0.9738 - val_loss: 0.2154 - val_accuracy: 0.9429\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0433 - accuracy: 0.9878 - val_loss: 0.2052 - val_accuracy: 0.9453\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0201 - accuracy: 0.9955 - val_loss: 0.2025 - val_accuracy: 0.9511\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 4s 122us/sample - loss: 0.0089 - accuracy: 0.9990 - val_loss: 0.1945 - val_accuracy: 0.9543\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.0047 - accuracy: 0.9999 - val_loss: 0.1978 - val_accuracy: 0.9551\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9558\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1995 - val_accuracy: 0.9560\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2023 - val_accuracy: 0.9567\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9567\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9573\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9578\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9573\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2074 - val_accuracy: 0.9575\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 9.2798e-04 - accuracy: 1.0000 - val_loss: 0.2085 - val_accuracy: 0.9577\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 8.5673e-04 - accuracy: 1.0000 - val_loss: 0.2093 - val_accuracy: 0.9577\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 7.9373e-04 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9579\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 4s 122us/sample - loss: 7.3972e-04 - accuracy: 1.0000 - val_loss: 0.2115 - val_accuracy: 0.9577\n",
      "16000/16000 [==============================] - 1s 40us/sample - loss: 0.2169 - accuracy: 0.9567\n",
      "[CV]  learning_rate=0.0023693222883062726, n_hidden=4, n_neurons=364, n_softmax=10, total= 1.2min\n",
      "[CV] learning_rate=0.0023693222883062726, n_hidden=4, n_neurons=364, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 4s 132us/sample - loss: 1.0013 - accuracy: 0.8618 - val_loss: 0.2766 - val_accuracy: 0.9171\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.1632 - accuracy: 0.9500 - val_loss: 0.2229 - val_accuracy: 0.9367\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0859 - accuracy: 0.9729 - val_loss: 0.1894 - val_accuracy: 0.9475\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0439 - accuracy: 0.9871 - val_loss: 0.1925 - val_accuracy: 0.9478\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 0.0216 - accuracy: 0.9948 - val_loss: 0.1968 - val_accuracy: 0.9514\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.1870 - val_accuracy: 0.9546\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.0056 - accuracy: 0.9997 - val_loss: 0.1881 - val_accuracy: 0.9563\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 4s 122us/sample - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.1884 - val_accuracy: 0.9572\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1918 - val_accuracy: 0.9575\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9575\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1960 - val_accuracy: 0.9581\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 4s 123us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1967 - val_accuracy: 0.9583\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1981 - val_accuracy: 0.9584\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1993 - val_accuracy: 0.9589\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 9.9659e-04 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 0.9582\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 4s 122us/sample - loss: 9.1012e-04 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9586\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 8.4023e-04 - accuracy: 1.0000 - val_loss: 0.2029 - val_accuracy: 0.9587\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 7.7976e-04 - accuracy: 1.0000 - val_loss: 0.2032 - val_accuracy: 0.9590\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 4s 118us/sample - loss: 7.2652e-04 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 0.9589\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 4s 122us/sample - loss: 6.8089e-04 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9588\n",
      "16000/16000 [==============================] - 1s 41us/sample - loss: 0.2106 - accuracy: 0.9586\n",
      "[CV]  learning_rate=0.0023693222883062726, n_hidden=4, n_neurons=364, n_softmax=10, total= 1.3min\n",
      "[CV] learning_rate=0.0023693222883062726, n_hidden=4, n_neurons=364, n_softmax=10 \n",
      "Train on 32000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "32000/32000 [==============================] - 4s 137us/sample - loss: 1.1390 - accuracy: 0.8598 - val_loss: 0.2948 - val_accuracy: 0.9178\n",
      "Epoch 2/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.1742 - accuracy: 0.9462 - val_loss: 0.2275 - val_accuracy: 0.9337\n",
      "Epoch 3/100\n",
      "32000/32000 [==============================] - 4s 122us/sample - loss: 0.1026 - accuracy: 0.9682 - val_loss: 0.2066 - val_accuracy: 0.9444\n",
      "Epoch 4/100\n",
      "32000/32000 [==============================] - 4s 123us/sample - loss: 0.0581 - accuracy: 0.9817 - val_loss: 0.1912 - val_accuracy: 0.9504\n",
      "Epoch 5/100\n",
      "32000/32000 [==============================] - 4s 122us/sample - loss: 0.0324 - accuracy: 0.9914 - val_loss: 0.1936 - val_accuracy: 0.9511\n",
      "Epoch 6/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0181 - accuracy: 0.9961 - val_loss: 0.1914 - val_accuracy: 0.9532\n",
      "Epoch 7/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 0.0099 - accuracy: 0.9987 - val_loss: 0.1909 - val_accuracy: 0.9565\n",
      "Epoch 8/100\n",
      "32000/32000 [==============================] - 4s 122us/sample - loss: 0.0058 - accuracy: 0.9996 - val_loss: 0.1945 - val_accuracy: 0.9557\n",
      "Epoch 9/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0038 - accuracy: 0.9999 - val_loss: 0.1998 - val_accuracy: 0.9570\n",
      "Epoch 10/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.2002 - val_accuracy: 0.9567\n",
      "Epoch 11/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9573\n",
      "Epoch 12/100\n",
      "32000/32000 [==============================] - 4s 123us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9567\n",
      "Epoch 13/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9578\n",
      "Epoch 14/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.2089 - val_accuracy: 0.9577\n",
      "Epoch 15/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2100 - val_accuracy: 0.9579\n",
      "Epoch 16/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2116 - val_accuracy: 0.9578\n",
      "Epoch 17/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.2124 - val_accuracy: 0.9586\n",
      "Epoch 18/100\n",
      "32000/32000 [==============================] - 4s 119us/sample - loss: 9.7549e-04 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9582\n",
      "Epoch 19/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 9.0141e-04 - accuracy: 1.0000 - val_loss: 0.2147 - val_accuracy: 0.9583\n",
      "Epoch 20/100\n",
      "32000/32000 [==============================] - 4s 120us/sample - loss: 8.4160e-04 - accuracy: 1.0000 - val_loss: 0.2161 - val_accuracy: 0.9582\n",
      "Epoch 21/100\n",
      "32000/32000 [==============================] - 4s 121us/sample - loss: 7.8331e-04 - accuracy: 1.0000 - val_loss: 0.2168 - val_accuracy: 0.9583\n",
      "16000/16000 [==============================] - 1s 39us/sample - loss: 0.2111 - accuracy: 0.9594\n",
      "[CV]  learning_rate=0.0023693222883062726, n_hidden=4, n_neurons=364, n_softmax=10, total= 1.4min\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 78.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.9633 - accuracy: 0.8798 - val_loss: 0.2471 - val_accuracy: 0.9301\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1561 - accuracy: 0.9537 - val_loss: 0.1901 - val_accuracy: 0.9454\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0914 - accuracy: 0.9724 - val_loss: 0.1684 - val_accuracy: 0.9517\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 5s 112us/sample - loss: 0.0567 - accuracy: 0.9831 - val_loss: 0.1570 - val_accuracy: 0.9580\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 0.0361 - accuracy: 0.9901 - val_loss: 0.1574 - val_accuracy: 0.9577\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 0.0225 - accuracy: 0.9942 - val_loss: 0.1611 - val_accuracy: 0.9567\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0135 - accuracy: 0.9971 - val_loss: 0.1581 - val_accuracy: 0.9607\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0080 - accuracy: 0.9989 - val_loss: 0.1524 - val_accuracy: 0.9611\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.1570 - val_accuracy: 0.9625\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0034 - accuracy: 0.9998 - val_loss: 0.1578 - val_accuracy: 0.9628\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0023 - accuracy: 0.9999 - val_loss: 0.1601 - val_accuracy: 0.9629\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1620 - val_accuracy: 0.9631\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1638 - val_accuracy: 0.9634\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1655 - val_accuracy: 0.9633\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1671 - val_accuracy: 0.9637\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.1677 - val_accuracy: 0.9642\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 9.2846e-04 - accuracy: 1.0000 - val_loss: 0.1689 - val_accuracy: 0.9636\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 8.4414e-04 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9643\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 5s 113us/sample - loss: 7.7948e-04 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9644\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 7.1962e-04 - accuracy: 1.0000 - val_loss: 0.1727 - val_accuracy: 0.9641\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 6.7138e-04 - accuracy: 1.0000 - val_loss: 0.1734 - val_accuracy: 0.9646\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 6.2520e-04 - accuracy: 1.0000 - val_loss: 0.1745 - val_accuracy: 0.9644\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 5.8791e-04 - accuracy: 1.0000 - val_loss: 0.1751 - val_accuracy: 0.9647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000016F315DB448>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000016F375A0E08>,\n",
       "                                        'n_hidden': [2, 3, 4],\n",
       "                                        'n_neurons': array([  1,   2,   3,   4,   5,   6,   7,   8...\n",
       "       443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n",
       "       456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "       469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "       482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "       495, 496, 497, 498, 499, 500]),\n",
       "                                        'n_softmax': [10, 20]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [2, 3, 4],\n",
    "    \"n_neurons\": np.arange(1, 501),\n",
    "    \"n_softmax\": [10, 20],\n",
    "    \"learning_rate\": reciprocal(1e-3, 3e-3),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(monitor='accuracy', patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0023693222883062726,\n",
       " 'n_hidden': 4,\n",
       " 'n_neurons': 364,\n",
       " 'n_softmax': 10}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21286418770933294"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x16f3d344108>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x16f3b2b35c8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.1610 - accuracy: 0.9669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16099024338480403, 0.9669]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b>: the accuracy score improved a bit more compared to the previous attempt but it's not enough. The accuracy scores through out the grid search ranged from ~95-96% which was a bit encouraging so we decided to take a look back at how we process the data from the very beginning to see if we could do something with it to help us achieve the goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Log 8\n",
    "\n",
    "At this point, we decided to scale the data just like what the chapter notebook did and train the best model we obtained above on the scaled set to see if we could make any improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled, X_train_scaled, X_test_scaled = X_val / 255., X_train / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the model\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x16f3b2b35c8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 6s 123us/sample - loss: 1.7548 - accuracy: 0.9256 - val_loss: 0.8441 - val_accuracy: 0.8767\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.4918 - accuracy: 0.8909 - val_loss: 0.3643 - val_accuracy: 0.9018\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.3124 - accuracy: 0.9129 - val_loss: 0.2907 - val_accuracy: 0.9205\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.2595 - accuracy: 0.9259 - val_loss: 0.2552 - val_accuracy: 0.9293\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.2277 - accuracy: 0.9342 - val_loss: 0.2282 - val_accuracy: 0.9365\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.2040 - accuracy: 0.9406 - val_loss: 0.2086 - val_accuracy: 0.9404\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.1859 - accuracy: 0.9458 - val_loss: 0.1948 - val_accuracy: 0.9452\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.1703 - accuracy: 0.9512 - val_loss: 0.1822 - val_accuracy: 0.9477\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.1583 - accuracy: 0.9540 - val_loss: 0.1721 - val_accuracy: 0.9518\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1474 - accuracy: 0.9573 - val_loss: 0.1607 - val_accuracy: 0.9551\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.1383 - accuracy: 0.9598 - val_loss: 0.1536 - val_accuracy: 0.9572\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.1302 - accuracy: 0.9626 - val_loss: 0.1461 - val_accuracy: 0.9598\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.1230 - accuracy: 0.9642 - val_loss: 0.1428 - val_accuracy: 0.9596\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.1166 - accuracy: 0.9662 - val_loss: 0.1387 - val_accuracy: 0.9614\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.1108 - accuracy: 0.9679 - val_loss: 0.1325 - val_accuracy: 0.9619\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1056 - accuracy: 0.9697 - val_loss: 0.1306 - val_accuracy: 0.9626\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.1007 - accuracy: 0.9711 - val_loss: 0.1237 - val_accuracy: 0.9646\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0963 - accuracy: 0.9726 - val_loss: 0.1210 - val_accuracy: 0.9654\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0924 - accuracy: 0.9736 - val_loss: 0.1190 - val_accuracy: 0.9663\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0885 - accuracy: 0.9743 - val_loss: 0.1161 - val_accuracy: 0.9661\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0846 - accuracy: 0.9756 - val_loss: 0.1124 - val_accuracy: 0.9682\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0815 - accuracy: 0.9764 - val_loss: 0.1103 - val_accuracy: 0.9678\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0781 - accuracy: 0.9774 - val_loss: 0.1076 - val_accuracy: 0.9690\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0750 - accuracy: 0.9789 - val_loss: 0.1063 - val_accuracy: 0.9687\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0725 - accuracy: 0.9792 - val_loss: 0.1040 - val_accuracy: 0.9708\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0697 - accuracy: 0.9804 - val_loss: 0.1031 - val_accuracy: 0.9702\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0672 - accuracy: 0.9812 - val_loss: 0.1014 - val_accuracy: 0.9703\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0646 - accuracy: 0.9819 - val_loss: 0.1023 - val_accuracy: 0.9706\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0623 - accuracy: 0.9828 - val_loss: 0.0997 - val_accuracy: 0.9712\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0600 - accuracy: 0.9835 - val_loss: 0.0975 - val_accuracy: 0.9707\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0578 - accuracy: 0.9839 - val_loss: 0.0963 - val_accuracy: 0.9723\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0559 - accuracy: 0.9847 - val_loss: 0.0957 - val_accuracy: 0.9727\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0541 - accuracy: 0.9853 - val_loss: 0.0945 - val_accuracy: 0.9726\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 6s 122us/sample - loss: 0.0520 - accuracy: 0.9859 - val_loss: 0.0929 - val_accuracy: 0.9733\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 6s 120us/sample - loss: 0.0503 - accuracy: 0.9866 - val_loss: 0.0928 - val_accuracy: 0.9722\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 6s 121us/sample - loss: 0.0487 - accuracy: 0.9867 - val_loss: 0.0910 - val_accuracy: 0.9737\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0467 - accuracy: 0.9876 - val_loss: 0.0912 - val_accuracy: 0.9727\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0453 - accuracy: 0.9882 - val_loss: 0.0901 - val_accuracy: 0.9737\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0436 - accuracy: 0.9886 - val_loss: 0.0897 - val_accuracy: 0.9736\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0422 - accuracy: 0.9889 - val_loss: 0.0895 - val_accuracy: 0.9735\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0407 - accuracy: 0.9894 - val_loss: 0.0900 - val_accuracy: 0.9732\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 6s 119us/sample - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.0880 - val_accuracy: 0.9742\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0378 - accuracy: 0.9905 - val_loss: 0.0889 - val_accuracy: 0.9734\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0367 - accuracy: 0.9908 - val_loss: 0.0884 - val_accuracy: 0.9732\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0351 - accuracy: 0.9913 - val_loss: 0.0868 - val_accuracy: 0.9744\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0341 - accuracy: 0.9915 - val_loss: 0.0875 - val_accuracy: 0.9737\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0328 - accuracy: 0.9919 - val_loss: 0.0873 - val_accuracy: 0.9730\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0316 - accuracy: 0.9926 - val_loss: 0.0861 - val_accuracy: 0.9739\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0305 - accuracy: 0.9927 - val_loss: 0.0862 - val_accuracy: 0.9734\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0295 - accuracy: 0.9930 - val_loss: 0.0859 - val_accuracy: 0.9746\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.0861 - val_accuracy: 0.9747\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0274 - accuracy: 0.9939 - val_loss: 0.0863 - val_accuracy: 0.9736\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 6s 118us/sample - loss: 0.0266 - accuracy: 0.9940 - val_loss: 0.0855 - val_accuracy: 0.9740\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0256 - accuracy: 0.9943 - val_loss: 0.0852 - val_accuracy: 0.9746\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0246 - accuracy: 0.9946 - val_loss: 0.0863 - val_accuracy: 0.9737\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0237 - accuracy: 0.9951 - val_loss: 0.0858 - val_accuracy: 0.9746\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0229 - accuracy: 0.9954 - val_loss: 0.0864 - val_accuracy: 0.9748\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0221 - accuracy: 0.9955 - val_loss: 0.0859 - val_accuracy: 0.9750\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 6s 116us/sample - loss: 0.0214 - accuracy: 0.9959 - val_loss: 0.0854 - val_accuracy: 0.9746\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0206 - accuracy: 0.9960 - val_loss: 0.0853 - val_accuracy: 0.9757\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0199 - accuracy: 0.9965 - val_loss: 0.0859 - val_accuracy: 0.9747\n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 6s 117us/sample - loss: 0.0191 - accuracy: 0.9965 - val_loss: 0.0869 - val_accuracy: 0.9748\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 6s 115us/sample - loss: 0.0184 - accuracy: 0.9969 - val_loss: 0.0860 - val_accuracy: 0.9753\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 5s 114us/sample - loss: 0.0177 - accuracy: 0.9970 - val_loss: 0.0867 - val_accuracy: 0.9759\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=100,\n",
    "                  validation_data=(X_val_scaled, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.0815 - accuracy: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08152713977500098, 0.9756]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b>: the accuracy did improve compared to the ones of the previous attempts, still not 98% as we expected, but very close. However, we clarified ourselves another fact that scaling the dataset does matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Documentation of Progress Log\n",
    "\n",
    "The log includes two kinds of entries that we came across whilst working on this assignment, they are problems and investigations. The following is our list of problem-solution pairs. Each entry corresponds to a checkpoint tag (i.e. \"Progress Log [number]\") throughout the process of building the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We realised that in order to use tensorflow (i.e. import the package for furture use), we had to have it installed beforehand. After spending a while to do some google search (i.e. choosing what is the most reliable link to follow), we managed to find a solution which is the following link https://www.tensorflow.org/install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Both of us had the up-to-date version of the chapter 10 notebook and we knew that there were already a solution for exercise 10, so we were confused about what exactly we had to do for this lab. After reading Prof. Basye's email, we decided that we would try processing the training and test sets in some different ways to see how it would affect the accuracy score in the end. For example, we would use a different ratio to split the full training set into validation and smaller training sets and not scale the sets by dividing by 255 (i.e. just leave them be) to see how our model would react to them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Initially, we built a random model which is kind of similar to one of the models in the chapter 10 notebook but we picked a different learning rate (layer1 = 300, layer2 = 100, layer3 = 10, learningRate = 1e-3, epochs = 30). The model achieved an accuracy score of about 94% which was pretty good in general, but our goal was to come up with a model ourselves that can achieve at least pretty much the same accuracy score as the one in the chapter notebook. Still, we considered that as a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. In order to try many different neural networks at once we figured that looking at only the first few epochs would give a good indication of what the total accuracy score would be after 30-50 epochs. We set up a for loop and looped through 16 different tests with different values for layer1, layer2, layer3, and learningRate. From that we found two tests in particular that had above a 95% accuracy after only 5 epochs. We then these two tests at 50 epochs to see what accuracy score we could get. Both of these tests had values:\n",
    "\n",
    "    layer1 = 500, layer2 = 500, learningRate = 0.001 with the only difference being layer3 = 10 and 20 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. With these two tests being our best from our earlier for loop we were surprised to find that both of them only received 96.25% and 96.24% accuracy respectively, neither being above or close to ur 98% accuracy goal. At this point we needed to take a step back and did some more reading into the chapter 10 notebook, looking at what our ML legend Geron had done to make the NN work so well. Initially we were curious about two things: changing the network size (and structure) and going through more epochs. Our earlier two tests were both incredibly similar so we realized we had to change up something bigger than we had before in order to get a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. One of the first things we realized is there shouldn't be much of a need to test farther than 30 or 50 epochs. It takes a long time to run these and if you're test isn't close to 98% by 30 epochs it probably isn't going to get much closer. This can easily be seen by Geron's example where they test up to 100 epochs. It's clear that, especially for our purposes of testing on not very powerful laptops, testing with much higher epochs than 30 isn't worth the time or the effort. Instead, we should only test above 30 epochs on a structure we are certain is going to work well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. We did some more testing, and this time with Keras Regressor and Grid Search. Most of the results finished at the range of 95-96% which was disappointing. This example goes back to the issue explained in log 6, that testing these networks take time and it is difficult to see exactly what would be best. At this point we are unsure exactly how to improve this model much further than ~96% accuracy. What is especially interesting is how structures that are built very differently produce surprisingly similar results. It's one of the main reasons why it is difficult to know exactly what to do next or what to change next. At this point we expect that there may be an issue in the fact that we didn't scale the data and how we splitted the datapoints at the start of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. We decided to scale the data just like what the chapter notebook did and then trained the best model obtained from the Grid Search on the scaled training set. As a result, our model achieved an accuracy score of 97.44% which was the best compared to the ones of the previous attempts. Even though it was not 98% as we expected, but we got closer to our goal and managed to somewhat clarify the fact that the way we processed our data at the beginning matters in terms of training the model. Also, we admit that our approach to the problem was not as professional as the solution but it still managed to do a pretty good job."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
